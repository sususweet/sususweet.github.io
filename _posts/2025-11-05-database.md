---
layout: post
title: 物联网面试
categories: [Basis]
description: 物联网面试题
keywords: MySQL, Java, QPS
mermaid: false
sequence: false
flow: false
mathjax: false
mindmap: false
mindmap2: false
---

# 数据库慢查询：从定位到优化，一文搞定性能瓶颈

### 一、先搞懂：什么是数据库慢查询？​

简单来说，慢查询就是**执行时间超过预设阈值的 SQL 语句**。比如我们设定 “执行时间超过 2 秒的 SQL 是慢查询”，那么所有运行时长≥2 秒的 SELECT/UPDATE/DELETE 语句，都会被归为慢查询。​

为什么要关注慢查询？​

* **少量慢查询可能导致接口超时，影响用户体验；​**

* **大量慢查询会占用数据库 CPU、内存资源，甚至拖垮整个数据库，引发服务雪崩。​**

所以，定位并优化慢查询，是保障数据库性能的核心手段。

### 二、实战第一步：开启并配置慢查询日志​

不同数据库（MySQL、PostgreSQL 等）开启慢查询的方式略有差异，这里以最常用的MySQL为例，讲解具体操作。​

#### 1\. 先检查当前慢查询配置​

登录 MySQL 终端，执行以下命令，查看当前慢查询是否开启、阈值是多少：​

> \-\- 查看慢查询日志是否开启（1=开启，0=关闭）​
> 
> show variables like 'slow\_query\_log';​
> 
> \-\- 查看慢查询阈值（单位：秒，默认10秒，可根据业务调整）​
> 
> show variables like 'long\_query\_time';​
> 
> \-\- 查看慢查询日志存储路径​
> 
> show variables like 'slow\_query\_log_file';​

#### 2\. 两种开启方式（临时 / 永久）​

##### （1）临时开启（重启 MySQL 后失效）​

适合临时排查问题，无需修改配置文件：

> \-\- 开启慢查询日志
> 
> set global slow\_query\_log = 1;
> 
> \-\- 设置阈值为2秒（即执行超过2秒的SQL会被记录）
> 
> set global long\_query\_time = 2;
> 
> \-\- （可选）自定义日志存储路径（需确保MySQL有写入权限）
> 
> set global slow\_query\_log_file = '/var/log/mysql/slow.log';

注意：设置后需重新登录 MySQL 终端，才能看到更新后的配置。

##### （2）永久开启（推荐）​

修改 MySQL 配置文件（Linux 路径通常是/etc/my.cnf，Windows 是my.ini），添加以下内容：​

> \[mysqld\]​
> 
> \# 开启慢查询日志​
> 
> slow\_query\_log = 1​
> 
> \# 慢查询阈值（单位：秒）​
> 
> long\_query\_time = 2​
> 
> \# 慢查询日志路径​
> 
> slow\_query\_log_file = /var/log/mysql/slow.log​
> 
> \# （可选）记录未使用索引的查询（即使执行很快，也可能是潜在问题）​
> 
> log\_queries\_not\_using\_indexes = 1​

添加后重启 MySQL 服务，配置即可生效：​

> \# Linux重启命令​
> 
> systemctl restart mysqld​
> 
> \# Windows重启命令（需以管理员身份执行）​
> 
> net stop mysql && net start mysql​

### 三、关键一步：分析慢查询日志，定位问题 SQL​

开启慢查询日志后，数据库会自动记录符合条件的 SQL。接下来需要通过工具分析日志，找出 “罪魁祸首”。​

#### 1\. 用 MySQL 自带工具：mysqldumpslow（简单高效）​

MySQL 默认提供mysqldumpslow工具，无需额外安装，适合快速分析日志。​

常用命令示例：​

> \# 1\. 按查询次数排序，显示前10条慢查询（最常用）​
> 
> mysqldumpslow -s c -t 10 /var/log/mysql/slow.log​
> 
> ​
> 
> \# 2\. 按执行时间排序（降序），显示前5条慢查询​
> 
> mysqldumpslow -s t -t 5 /var/log/mysql/slow.log​
> 
> ​
> 
> \# 3\. 按锁定时间排序，显示前3条慢查询​
> 
> mysqldumpslow -s l -t 3 /var/log/mysql/slow.log​
> 
> ​
> 
> \# 4\. 过滤包含“order by”的慢查询​
> 
> mysqldumpslow -g "order by" /var/log/mysql/slow.log​

参数说明：​

* -s：排序方式（c = 查询次数，t = 执行时间，l = 锁定时间，r = 返回行数）；​

* -t：显示前 N 条结果；​

* -g：按关键字过滤（支持正则表达式）。​

分析结果解读：​

执行命令后，会看到类似以下的输出：​

> Count: 10 Time=3.20s (32.00s) Lock=0.00s (0.00s) Rows=1000.0 (10000.0), root\[root\]@localhost​
> 
> SELECT * FROM order WHERE user_id = N​

关键信息解读：​

* Count:10：该 SQL 执行了 10 次；​

* Time=3.20s：单次执行时间 3.2 秒，总时间 32 秒；​

* Rows=1000：单次返回 1000 行数据；​

* 最后一行是具体的 SQL 语句（N是占位符，实际日志会显示真实参数）。

#### 2\. 可视化工具：Percona Toolkit（适合复杂场景）​

如果慢查询日志量大，mysqldumpslow的输出不够直观，可以用 Percona Toolkit 的pt-query-digest工具，它能生成更详细的分析报告（含执行频率、锁等待时间、索引使用情况等）。​

安装与使用（以 Linux 为例）：​

> \# 1\. 安装Percona Toolkit​
> 
> yum install percona-toolkit -y​
> 
> ​
> 
> \# 2\. 分析慢查询日志，生成详细报告​
> 
> pt-query-digest /var/log/mysql/slow.log > slow_analysis报告.txt​

打开生成的slow_analysis报告.txt，会看到按 “查询指纹” 分组的慢查询，每组都包含执行统计、索引使用情况、SQL 语句等，能快速定位 “执行次数多 + 耗时久” 的核心问题 SQL。

### 四、核心解决方案：慢查询优化技巧（实战总结）​

找到问题 SQL 后，如何优化？以下是经过实战验证的 5 个核心技巧，覆盖 90% 以上的慢查询场景。​

#### 1\. 优化 SQL 语句：避免 “低效写法”​

这是最基础也最有效的优化方式，很多慢查询都是 “SQL 写法不当” 导致的。​

常见错误写法与优化：​

| 错误写法                                                                                               | 优化写法​                                           | 原因​                      |
| -------------------------------------------------------------------------------------------------- | ----------------------------------------------- | ------------------------ |
| SELECT * FROM order​                                                                               | SELECT id, order_no, amount FROM order​         | 避免查询无用列，减少数据传输量​         |
| SELECT * FROM user WHERE name LIKE '%张%'​                                                          | SELECT id, name FROM user WHERE name LIKE '张%'​ | 左模糊（% 开头）会导致索引失效，右模糊不会​  |
| SELECT * FROM order WHERE create\_time > '2024-01-01' AND create\_time < '2024-01-31' ORDER BY id​ | 同上，确保create_time和id有索引​                         | 无索引会导致全表扫描 \+ 文件排序，耗时极长​ |
| SELECT count(*) FROM order WHERE status = 1​                                                       | 同上，给status建索引​                                  | 无索引时，数据库需扫描全表统计行数​       |

关键原则：​

* 只查需要的列，不写SELECT *；​

* 避免在索引列上做函数操作（如DATE(create_time) = '2024-01-01'）；​

* 避免用!=、<>、NOT IN等操作符，会导致索引失效；​

* 复杂查询拆分成简单查询（如多表 JOIN 拆成多次单表查询）。​

#### 2\. 优化索引：给 “关键列” 建索引​

索引是 “加速查询的利器”，但不是 “越多越好”，需给 “查询频繁的列” 建合适的索引。​

必建索引的场景：​

* WHERE 条件中频繁出现的列（如user_id、status）；​

* JOIN 关联的列（如order.user_id关联[user.id](http://user.id/ "user.id")）；​

* ORDER BY/GROUP BY 的列（如create_time、amount）。​

示例：​

> \-\- 给order表的user\_id和create\_time建联合索引（适合多条件查询）​
> 
> CREATE INDEX idx\_order\_user\_create ON order(user\_id, create_time);​
> 
> ​
> 
> \-\- 给user表的name建索引（适合模糊查询“张%”）​
> 
> CREATE INDEX idx\_user\_name ON user(name);​

索引注意事项：​

* 单表索引不超过 5 个（过多会拖慢增删改操作，因为索引需要维护）；​

* 避免重复索引（如主键默认是聚簇索引，无需再给主键建普通索引）；​

* 小表（数据量 < 1 万行）无需建索引（全表扫描更快）。​

#### 3\. 优化表结构：大表拆分​

当表数据量超过 100 万行，即使有索引，查询也可能变慢，此时需要 “拆分表”。​

##### （1）水平分表（按行拆分）​

将一张大表按 “时间” 或 “用户 ID” 拆分成多个小表，每个表的结构相同。​

示例：​

* 订单表（order）按时间拆分为order\_202401、order\_202402、order_202403（每月一张表）；​

* 用户表（user）按用户 ID 哈希拆分为user\_0、user\_1、user\_2（共 3 张表，通过user\_id % 3决定存哪张表）。​

##### （2）垂直分表（按列拆分）​

将一张表的 “热门列” 和 “冷门列” 分开，减少单表数据量。​

示例：​

* 用户表（user）拆分为user\_base（存 id、name、phone 等常用列）和user\_detail（存 address、avatar、introduction 等不常用列）；​

* 查询用户基本信息时，只需查user_base，避免加载无用的大字段（如 avatar 的 URL）。​

#### 4\. 加缓存：减少数据库访问​

对于 “查询频繁、数据变化少” 的慢查询（如商品详情、用户信息），可以用 Redis 等缓存工具，将查询结果缓存起来，下次直接从缓存获取，无需访问数据库。​

示例流程：​

1. 客户端查询商品详情：先查 Redis，若有数据直接返回；​

2. 若 Redis 无数据，查数据库，获取结果后存入 Redis（设置过期时间，如 1 小时）；​

3. 下次查询时，直接从 Redis 获取，耗时从 “秒级” 降到 “毫秒级”。​

#### 5\. 读写分离：分散数据库压力​

如果数据库 “读多写少”（如电商网站，查询商品远多于下单），可以搭建 “主从复制” 架构，让主库负责写操作（INSERT/UPDATE/DELETE），从库负责读操作（SELECT），分散数据库压力。​

示例：​

* 主库：处理用户下单、修改信息等写操作；​

* 从库：处理商品列表查询、订单历史查询等读操作；​

* 慢查询大多发生在 “读操作”，从库可以有效分担压力。​

### 五、总结：慢查询优化的核心思路​

慢查询优化不是 “一蹴而就” 的，而是 “定位→分析→优化→验证” 的循环过程，核心思路可以总结为 3 点：​

1. 先定位：通过慢查询日志，找到执行时间长、执行次数多的 SQL；​

2. 再分析：查看 SQL 是否用了索引、是否有低效写法、表数据量是否过大；​

3. 后优化：优先优化 SQL 写法和索引（成本最低、效果最明显），再考虑分表、缓存、读写分离（成本较高，适合大流量场景）。​ 

# MySQL 查询优化器

### 一、查询优化

#### 1、查询优化器 (Query Optimizer)

MySQL查询优化器（Query Optimizer）是[MySQL数据库](https://so.csdn.net/so/search?q=MySQL%E6%95%B0%E6%8D%AE%E5%BA%93&spm=1001.2101.3001.7020)管理系统中的一个关键组件，负责分析和选择最有效的执行计划来执行SQL查询。查询优化器的目标是尽可能减少查询的执行时间和资源消耗，从而提高查询性能。

**查询语句不同关键字（where、jion、limit、group by、having等）执行时，访问的先后顺序?**  

查询中用到的关键词主要包含六个，并且他们的顺序依次为  

select–from–where–group by–having–order by

##### （1）查询优化器的工作原理

1、解析查询：将SQL语句解析为内部表示形式（通常是抽象语法树，AST），并进行语法和语义检查。  
2、生成可能的执行计划：根据表结构、索引、统计信息等，生成多个可能的查询执行计划。  
3、评估执行成本：为每个可能的执行计划估算其执行成本（如I/O操作次数、CPU使用时间等），并选择成本最低的执行计划。  
4、执行查询：按照选定的执行计划执行查询，并返回结果。

##### （2）查询优化器的工作流程

###### 1、解析查询

当用户提交一条SQL查询时，MySQL首先会通过解析器将SQL语句转换为内部表示形式（抽象语法树）。解析器会检查SQL语句的语法是否正确，并确保查询中引用的表、列和函数都存在且有效。  
**例如，假设我们有以下查询：**

    SELECT name, age FROM users WHERE age > 30;

解析器会将这条查询解析为一个内部表示形式，标识出SELECT、FROM、WHERE等关键字，以及它们对应的表名、列名和条件表达式。

###### 2、生成可能的执行计划

在解析完成后，查询优化器会生成多个可能的执行计划。执行计划描述了如何访问表中的数据、如何应用过滤条件、如何连接多个表等。

**查询优化器会考虑以下因素来生成不同的执行计划：**

* 表的访问顺序：如果查询涉及多个表，优化器会尝试不同的表连接顺序，以找到最优的顺序。
* 索引的选择：优化器会评估表上的所有可用索引，并决定是否使用某个索引来加速查询。
* 连接方法：对于多表查询，优化器会选择合适的连接方法（如嵌套循环连接、哈希连接、合并连接等）。
* 聚合和排序：如果查询包含GROUP BY或ORDER BY子句，优化器会决定如何高效地执行这些操作。

**示例：**

    SELECT u.name, o.order_date 
    FROM users u 
    JOIN orders o ON u.user_id = o.user_id 
    WHERE u.age > 30;

**对以上的sql，优化器可能会生成以下几种执行计划：**

* 先扫描users表，找到所有age > 30的用户，然后通过user_id索引查找对应的orders表记录。
* 先扫描orders表，找到所有订单，然后通过user_id索引查找对应的users表记录，并应用age > 30的过滤条件。

###### 3、评估执行成本

为了选择最优的执行计划，查询优化器会为每个可能的执行计划估算其执行成本。

**成本评估基于以下因素：**

* I/O成本：读取磁盘页面的数量。I/O操作通常是最耗时的部分，因此优化器会尽量减少磁盘I/O。
* CPU成本：CPU使用的时间。包括比较、计算、排序等操作的开销。
* 内存使用：查询执行过程中需要的内存资源。过多的内存使用可能导致缓存失效或交换到磁盘，影响性能。
* 表的大小和索引的覆盖性：优化器会考虑表的行数、索引的覆盖情况等因素。如果索引能够覆盖查询所需的所有列，则可以直接从索引中获取数据，而不需要访问表的数据页。
* 统计信息：优化器会使用表和索引的统计信息（如行数、列的唯一值数量、索引的选择性等）来估计查询的执行成本。统计信息越准确，优化器的选择就越合理。

例如，假设users表有100万行数据，而orders表有500万行数据。优化器会根据统计信息估算不同执行计划的I/O和CPU成本，并选择成本最低的计划。

###### 4、执行查询

一旦选择了最优的执行计划，MySQL就会按照该计划执行查询，并返回结果。查询优化器还会将执行计划缓存起来，以便在后续相同的查询中重用，避免重复优化。

##### （3）查询优化器的关键技术

###### 1、索引选择

索引是查询优化器最重要的工具之一。优化器会根据查询条件、表结构和索引的覆盖性，选择最适合的索引。

**常见的索引类型包括：**

* B+树索引：适用于范围查询、精确匹配和排序操作。
* 哈希索引：适用于精确匹配查询，但不支持范围查询。
* 全文索引：适用于全文搜索。
* 空间索引：适用于地理空间数据的查询。

优化器会根据查询的条件和表的统计信息，评估每个索引的选择性和覆盖性。例如，如果查询只涉及索引中的列，优化器可能会选择使用覆盖索引（Covering Index），以避免额外的表扫描。

###### 2、连接优化

对于多表查询，优化器会决定如何连接这些表。

**常见的连接方法包括：**

* 嵌套循环连接（Nested Loop Join）：逐行扫描外层表，然后在内层表中查找匹配的记录。适用于小表或有索引的表。
* 哈希连接（Hash Join）：将一个表的数据加载到内存中的哈希表中，然后扫描另一个表并与哈希表进行匹配。适用于大表之间的连接。
* 合并连接（Merge Join）：适用于两个已经排序的表，通过合并两个有序的结果集来完成连接。适用于带有ORDER BY或GROUP BY的查询。

优化器会根据表的大小、索引的存在与否以及查询条件，选择最适合的连接方法。

###### 3、子查询优化

MySQL查询优化器还支持多种子查询优化技术，以提高子查询的执行效率。

**常见的子查询优化策略包括：**

* 子查询展开（Subquery Unnesting）：将子查询转换为等价的连接查询，以减少嵌套层次。
* 物化子查询（Materialization）：将子查询的结果物化为临时表，避免多次执行子查询。
* 半连接优化（Semi-Join Optimization）：对于EXISTS或IN子查询，优化器会将其转换为半连接操作，减少不必要的数据扫描。

###### 4、并行查询

在MySQL 8.0及更高版本中，查询优化器支持并行查询执行。对于大型查询，优化器可以将查询分解为多个并行任务，利用多核CPU提高查询性能。

**并行查询适用于以下场景：**

* 大规模表扫描
* 复杂的聚合操作
* 多表连接

并行查询的启用可以通过配置参数innodb\_parallel\_read_threads来控制。

###### 5、查询缓存

虽然MySQL 8.0及更高版本已经移除了传统的查询缓存（Query Cache），但优化器仍然会缓存执行计划。查询缓存的作用是存储之前执行过的查询结果，以便在相同查询再次执行时直接返回缓存的结果，而不必重新执行查询。虽然查询缓存可以提高某些查询的性能，但它也可能导致一致性问题，并且在高并发场景下效果不佳。

##### （4）如何查看查询优化器的行为

MySQL提供了多种工具和命令，帮助你查看查询优化器的行为和执行计划。以下是常用的工具和命令：

###### 1、EXPLAIN

EXPLAIN是最常用的工具，用于显示查询的执行计划。它可以帮助你了解优化器如何选择表、索引和连接方法。

**sql示例：**

    EXPLAIN SELECT name, age FROM users WHERE age > 30;

**EXPLAIN的输出包括以下列：**

* id：查询的标识符，标识查询的顺序。
* select_type：查询的类型（如简单查询、子查询、联合查询等）。
* table：当前操作的表。
* partitions：涉及的分区（如果有分区表）。
* type：访问类型（如ALL、index、range、ref等）。
* possible_keys：可能使用的索引。
* key：实际使用的索引。
* key_len：索引的长度。
* ref：与索引比较的列或常量。
* rows：估计需要扫描的行数。
* filtered：根据条件过滤后剩余的行数百分比。
* Extra：额外的信息，如是否使用临时表、是否进行排序等。

###### 2、SHOW WARNINGS

SHOW WARNINGS可以显示查询优化器在执行过程中生成的警告信息。这些警告信息可以帮助你发现潜在的问题，如未使用的索引、隐式类型转换等。  
**sql示例：**

    SHOW WARNINGS;

###### 3、Optimizer_Trace

Optimizer\_Trace是MySQL 5.6及更高版本中引入的功能，提供了更详细的查询优化过程跟踪。你可以通过设置系统变量optimizer\_trace来启用此功能，并查看优化器的决策过程。  
**sql示例：**

    SET optimizer_trace='enabled=on';
    SELECT name, age FROM users WHERE age > 30;
    SELECT * FROM INFORMATION_SCHEMA.OPTIMIZER_TRACE;

**运行结果：**  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c72dcc50af4947c7bb830b6828cbed52.png)

###### 4、Performance Schema

Performance Schema是MySQL的性能监控工具，提供了对查询执行的详细统计信息。你可以使用Performance Schema来跟踪查询的执行时间、I/O操作、锁争用等情况。  
**sql示例：**

    SELECT * FROM performance_schema.events_statements_current;

**运行结果：**  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c5bc9fb71cb34bebb0864a4ee9cbcd41.png)

#### 2、常见SQL优化手段

SQL查询优化是提高数据库性能的关键步骤，尤其是在处理大规模数据时。通过优化查询，可以减少I/O操作、降低CPU使用率、减少内存占用，并最终提升系统的响应速度。以下是常见的SQL优化手段，涵盖了从查询编写、索引设计到数据库配置等多个方面。

##### （1）创建合适的索引

索引是SQL查询优化中最重要且最有效的工具之一。合理的索引设计可以显著提高查询性能，尤其是对于大表和复杂的查询。以下是一些创建索引的最佳实践：

###### 1、覆盖索引（Covering Index）

覆盖索引是指索引中包含了查询所需的所有列，这样查询可以直接从索引中获取数据，而不需要访问表的数据页。这可以显著减少I/O操作。

**示例：**  
假设我们有一个查询SELECT name, age FROM users WHERE age > 30，可以在age和name上创建组合索引，使其成为覆盖索引。  
**sql示例：**

    CREATE INDEX idx_age_name ON users (age, name);

###### 2、组合索引（Composite Index）

组合索引是由多个列组成的索引。在创建组合索引时，应该将最常用的查询条件列放在前面，以提高索引的选择性。

**示例：**  
对于查询SELECT * FROM orders WHERE customer\_id = 1 AND order\_date > ‘2023-01-01’，可以在customer\_id和order\_date上创建组合索引。  
**sql示例：**

    CREATE INDEX idx_customer_order_date ON orders (customer_id, order_date);

###### 3、前缀索引（Prefix Index）

对于长字符串列（如VARCHAR），可以创建前缀索引，只索引字符串的前几个字符。这可以减少索引的大小，同时仍然提供良好的查询性能。

**示例：**  
假设我们有一个email列，可以创建一个前缀索引来索引前20个字符。  
**sql示例：**

    CREATE INDEX idx_email_prefix ON users (email(20));

###### 4、唯一索引（Unique Index）

如果某个列需要保证唯一性，建议使用唯一索引。唯一索引不仅可以确保数据的完整性，还可以加速基于该列的查询。

**示例：**  
对于user_id列，可以创建唯一索引。  
**sql示例：**

    CREATE UNIQUE INDEX idx_user_id ON users (user_id);

###### 5、避免过度索引

虽然索引可以提高查询性能，但过多的索引会增加插入、更新和删除操作的开销。因此，应该只在常用的查询条件上创建索引，避免为每个列都创建索引。

##### （2）优化查询语句

编写高效的SQL查询语句是提高性能的重要手段。以下是一些常见的查询优化技巧：

###### 1、避免使用SELECT *

尽量避免使用 SELECT *，因为它会返回所有列，即使某些列并不需要。这不仅增加了网络传输的数据量，还可能导致不必要的I/O操作。

**sql示例：**

    - 优化前：
    SELECT * FROM users WHERE age > 30;
    - 优化后：
    SELECT id, name, age FROM users WHERE age > 30;

###### 2、使用EXISTS替代IN

在子查询中，_EXISTS通常比IN更高效，尤其是在子查询返回大量结果时。EXISTS只需要找到一条匹配的记录即可终止查询，而IN需要遍历整个子查询结果集。_

**sql示例：**

    - 优化前：
    SELECT * FROM orders WHERE user_id IN (SELECT user_id FROM users WHERE age > 30);
    - 优化后：
    SELECT * FROM orders o WHERE EXISTS (SELECT 1 FROM users u WHERE u.user_id = o.user_id AND u.age > 30);

###### 3、使用JOIN替代子查询

对于多表查询，尽量使用JOIN代替嵌套子查询。JOIN通常比子查询更高效，因为优化器可以更好地优化连接操作。

**sql示例：**

    - 优化前：
    SELECT * FROM orders WHERE user_id IN (SELECT user_id FROM users WHERE age > 30);
    - 优化后：
    SELECT o.* 
    FROM orders o 
    JOIN users u ON o.user_id = u.user_id 
    WHERE u.age > 30;

###### 4、避免隐式类型转换

隐式类型转换会导致索引失效，因为数据库无法直接使用索引来加速查询。确保查询条件中的列和常量类型一致，避免不必要的类型转换。

**sql示例：**

    - 优化前：
    SELECT * FROM users WHERE age = '30';  -- 字符串与整数比较
    - 优化后：
    SELECT * FROM users WHERE age = 30;  -- 整数与整数比较

###### 5、分页查询优化

对于分页查询，尽量避免使用OFFSET，因为它会导致全表扫描。可以考虑使用主键或唯一列进行分页，或者使用覆盖索引。

**sql示例：**

    - 优化前：
    SELECT * FROM users LIMIT 1000 OFFSET 9000;
    - 优化后：
    SELECT * FROM users WHERE id > 9000 ORDER BY id LIMIT 1000;

###### 6、使用批量操作

在插入、更新或删除大量数据时，尽量使用批量操作，而不是逐行处理。批量操作可以减少与数据库的交互次数，显著提高性能。

**sql示例：**

    - 优化前：
    INSERT INTO users (name, age) VALUES ('Alice', 30);
    INSERT INTO users (name, age) VALUES ('Bob', 35);
    INSERT INTO users (name, age) VALUES ('Charlie', 40);
    - 优化后：
    INSERT INTO users (name, age) VALUES 
    ('Alice', 30),
    ('Bob', 35),
    ('Charlie', 40);

##### （3）优化表结构

合理的表结构设计可以显著提高查询性能。以下是一些建议：

###### 1、选择合适的数据类型

选择合适的数据类型不仅可以节省存储空间，还可以提高查询性能。尽量使用最小的数据类型，避免不必要的复杂类型。

**常用类型：**

* 整数类型：根据实际需求选择最小的整数类型（如TINYINT、SMALLINT、INT、BIGINT）。
* 字符类型：尽量使用VARCHAR而不是TEXT，并且为VARCHAR设置合理的长度限制。
* 日期和时间类型：使用DATE或DATETIME类型来存储日期和时间，而不是使用字符串。
* 布尔类型：MySQL没有专门的布尔类型，通常使用TINYINT(1)来表示布尔值（0或1）。

###### 2、使用分区表

对于大型表，可以考虑使用分区表（Partitioning）。分区表可以根据某些条件（如日期、范围、列表等）将数据分散到不同的物理存储区域，从而提高查询性能和管理效率。

**示例：**  
按年份对订单表进行分区。  
**sql示例：**

    CREATE TABLE orders (
        order_id INT AUTO_INCREMENT PRIMARY KEY,
        order_date DATE,
        amount DECIMAL(10, 2)
    ) PARTITION BY RANGE (YEAR(order_date)) (
        PARTITION p2020 VALUES LESS THAN (2021),
        PARTITION p2021 VALUES LESS THAN (2022),
        PARTITION p2022 VALUES LESS THAN (2023)
    );

###### 3、垂直拆分表

如果某个表包含大量的列，且某些列很少被查询，可以考虑将表进行垂直拆分。将不常用的列拆分到单独的表中，减少主表的宽度，从而提高查询性能。

**示例：**  
将用户的基本信息和详细信息拆分为两个表。  
**sql示例：**

    CREATE TABLE users_basic (
        user_id INT PRIMARY KEY,
        name VARCHAR(100),
        email VARCHAR(100)
    );
    
    CREATE TABLE users_detail (
        user_id INT PRIMARY KEY,
        address TEXT,
        phone_number VARCHAR(20),
        FOREIGN KEY (user_id) REFERENCES users_basic(user_id)
    );

###### 4、水平拆分表

对于非常大的表，可以考虑进行水平拆分（Sharding）。水平拆分是将表的数据按某种规则（如用户ID、地区等）分布到多个表或多个数据库实例中，以减少单个表的规模。

**示例：**  
按用户ID进行水平拆分。  
**sql示例：**

    CREATE TABLE users_0 (
        user_id INT PRIMARY KEY,
        name VARCHAR(100),
        email VARCHAR(100)
    );
    
    CREATE TABLE users_1 (
        user_id INT PRIMARY KEY,
        name VARCHAR(100),
        email VARCHAR(100)
    );

##### （4）优化数据库配置

合理的数据库配置可以显著提高查询性能。以下是一些常见的配置优化建议：

###### 1、调整缓冲区大小

MySQL提供了多种缓冲区来缓存查询结果、索引、表数据等。适当调整这些缓冲区的大小可以提高查询性能。

* InnoDB缓冲池（innodb\_buffer\_pool_size）：用于缓存InnoDB表的数据和索引。建议将其设置为服务器内存的70%左右。  
  **sql示例：**
  
  SET GLOBAL innodb_buffer_pool_size = 8G;

* 查询缓存（query\_cache\_size）：MySQL 8.0及更高版本已经移除了传统的查询缓存，但在MySQL 5.x版本中，可以适当调整查询缓存的大小。不过，查询缓存在高并发场景下效果不佳，建议谨慎使用。  
  **sql示例：**
  
  SET GLOBAL query_cache_size = 64M;

###### 2、启用并行查询

在MySQL 8.0及更高版本中，查询优化器支持并行查询执行。对于大型查询，启用并行查询可以利用多核CPU提高查询性能。

* 启用并行读取线程：  
  **示例：**
  
  SET GLOBAL innodb_parallel_read_threads = 4;

###### 3、调整事务隔离级别

MySQL支持四种事务隔离级别：READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ和SERIALIZABLE。默认情况下，MySQL使用REPEATABLE READ，但根据应用的需求，可以选择更低的隔离级别来提高并发性能。

* 设置事务隔离级别：  
  **sql示例：**
  
  SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;

###### 4、禁用不必要的日志

某些日志（如二进制日志、慢查询日志等）会增加I/O开销。如果不需要这些日志，可以禁用它们以提高性能。

* 禁用二进制日志：  
  **sql示例：**
  
  SET GLOBAL binlog_format = 'OFF';

* 禁用慢查询日志：  
  **sql示例：**
  
  SET GLOBAL slow_query_log = 'OFF';

##### （5）使用查询缓存

虽然MySQL 8.0及更高版本已经移除了传统的查询缓存，但你仍然可以通过其他方式实现类似的效果：

###### 1、使用Redis或Memcached

可以使用Redis或Memcached等内存缓存系统来缓存频繁访问的查询结果。缓存系统可以显著减少数据库的负载，特别是在高并发场景下。

###### 2、使用查询结果缓存

对于一些不经常变化的查询结果，可以考虑将结果缓存到文件或内存中，避免每次都从数据库中读取。

##### （6）监控和分析查询性能

定期监控和分析查询性能可以帮助你发现潜在的性能瓶颈，并及时采取优化措施。以下是一些常用的监控和分析工具：

###### 1、EXPLAIN

EXPLAIN是最常用的工具，用于显示查询的执行计划。它可以帮助你了解优化器如何选择表、索引和连接方法。

**sql示例：**

    EXPLAIN SELECT name, age FROM users WHERE age > 30;

###### 2、慢查询日志

慢查询日志记录了执行时间超过指定阈值的查询。通过分析慢查询日志，可以找出需要优化的查询。

* 启用慢查询日志：  
  **sql示例：**
  
  SET GLOBAL slow_query_log = 'ON';
  SET GLOBAL long_query_time = 1;  -- 记录执行时间超过1秒的查询为慢查询

###### 3、Performance Schema

Performance Schema是MySQL的性能监控工具，提供了对查询执行的详细统计信息。你可以使用Performance Schema来跟踪查询的执行时间、I/O 操作、锁争用等情况。

**sql示例：**

    SELECT * FROM performance_schema.events_statements_current;

###### 4、Optimizer_Trace

Optimizer Trace提供了详细的查询优化过程跟踪，帮助你了解优化器的决策过程。

* 启用Optimizer Trace：  
  **sql示例：**
  
  SET optimizer_trace='enabled=on';
  SELECT name, age FROM users WHERE age > 30;
  SELECT * FROM INFORMATION_SCHEMA.OPTIMIZER_TRACE;

##### （7）SQL查询优化总结

SQL查询优化是一个多方面的过程，涉及到索引设计、查询语句编写、表结构调整、数据库配置等多个方面。通过合理使用索引、优化查询语句、调整表结构和数据库配置，可以显著提高查询性能，减少资源消耗，并最终提升系统的响应速度。

**常见SQL优化手段包括：**  
1、创建合适的索引：使用覆盖索引、组合索引、前缀索引等，确保查询能够高效地使用索引。  
2、优化查询语句：避免使用SELECT ，使用EXISTS替代IN，使用JOIN替代子查询，避免隐式类型转换，优化分页查询。  
3、优化表结构：选择合适的数据类型，使用分区表、垂直拆分表、水平拆分表等技术。  
4、优化数据库配置：调整缓冲区大小、启用并行查询、调整事务隔离级别、禁用不必要的日志。  
5、使用查询缓存：使用Redis或Memcached等缓存系统，缓存频繁访问的查询结果。  
6、监控和分析查询性能：使用EXPLAIN、慢查询日志、Performance Schema和Optimizer Trace 等工具，监控和分析查询性能。

### 二、执行计划（EXPLAIN）

EXPLAIN是最常用的工具，用于显示查询的执行计划。它可以帮助你了解优化器如何选择表、索引和连接方法。

我们将使用一个常见的场景：用户订单系统，涉及users和orders两个表。并详细解释EXPLAIN的输出结果。

#### 1、创建测试数据

**sql示例：**

    -- 创建users表
    CREATE TABLE users (
        user_id INT AUTO_INCREMENT PRIMARY KEY,
        name VARCHAR(100),
        email VARCHAR(100),
        age INT
    );
    
    -- 创建 orders 表
    CREATE TABLE orders (
        order_id INT AUTO_INCREMENT PRIMARY KEY,
        user_id INT,
        order_date DATE,
        amount DECIMAL(10, 2),
        FOREIGN KEY (user_id) REFERENCES users(user_id)
    );
    
    -- 插入测试数据
    INSERT INTO users (name, email, age) VALUES 
    ('Alice', 'alice@example.com', 35),
    ('Bob', 'bob@example.com', 28),
    ('Charlie', 'charlie@example.com', 40),
    ('David', 'david@example.com', 25);
    
    INSERT INTO orders (user_id, order_date, amount) VALUES 
    (1, '2023-01-01', 100.00),
    (1, '2023-02-01', 200.00),
    (2, '2023-03-01', 150.00),
    (3, '2023-04-01', 300.00);

#### 2、查看未优化查询的执行计划

**sql示例：**

    EXPLAIN SELECT u.name, o.order_date, o.amount 
    FROM users u 
    JOIN orders o ON u.user_id = o.user_id 
    WHERE u.age > 30;

**运行结果：**  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0abeaf3b16984b21aae6d5a2e45fa12b.png)

#### 3、执行计划解释

1、id列：表示查询的优先级顺序。在这个例子中，id为1，表示这两行优先级一致。  
2、select_type列：表示查询的类型。SIMPLE表示这是一个简单的查询，不包含子查询或联合查询。  
3、table列：表示当前操作的表。第一个行是users表，第二个行是orders表。  
4、partitions列：表示涉及的分区（如果有分区表）。在这个例子中，没有使用分区表，因此该列为NULL。  
5、type列：表示访问类型。ALL表示全表扫描，ref表示通过索引进行查找。

* 对于users表，type为ALL，表示优化器选择了全表扫描，因为没有合适的索引可以使用。
* 对于orders表，type为ref，表示优化器使用了user_id索引来查找与users表匹配的记录。  
  6、possible\_keys列：表示可能使用的索引。对users表，possible\_keys为NULL，表示没有可用的索引；对于orders表，possible\_keys为user\_id，表示user_id是一个可能的索引。  
  7、key列：表示实际使用的索引。对于users表，key为NULL，表示没有使用索引；对于orders表，key为user\_id，表示使用了user\_id索引。  
  8、key\_len列：表示索引的长度。对于orders表，key\_len为5，表示user_id索引的长度为5字节（INT类型）。  
  9、ref列：表示与索引比较的列或常量。对于orders表，ref为demo1.u.user\_id，表示orders表中的user\_id列与users表中的user_id列进行比较。  
  10、rows列：表示优化器估计需要扫描的行数。对于users表，rows为 4，表示优化器估计需要扫描4行；对于orders表，rows为1，表示优化器估计每个users表的记录会匹配1行orders表的记录。  
  11、filtered列：表示根据条件过滤后剩余的行数百分比。对于users表，filtered为33.33%，表示大约有三分之一的记录满足age > 30的条件；对于orders表，filtered为100.00%，表示所有匹配的记录都符合条件。  
  12、Extra列：提供额外的信息。对于users表，Extra为Using where，表示使用了WHERE子句进行过滤；对于orders表，Extra为Using index，表示优化器只使用了索引中的列，而不需要访问表的数据页。

#### 4、索引优化查询

从执行计划中可以看出，users表进行了全表扫描（ALL），这在数据量较大时会导致性能问题。为了优化查询，我们可以采取以下措施：

* 创建索引  
  为users表的age列创建索引，以加速WHERE子句中的条件过滤。  
  **sql示例：**
  
  CREATE INDEX idx_age ON users (age);

* 创建覆盖索引  
  为users表创建一个覆盖索引，包含user_id和name列。这样查询可以直接从索引中获取所需的数据，而不需要访问表的数据页。  
  **sql示例：**
  
  CREATE INDEX idx_user_name_age ON users (age, user_id, name);

**运行结果：**  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/011453fe7f0f41fd943d4bd75b8da3b9.png)  
**优化后的执行计划解释：**  
1、type列：对于users表，type从ALL变为range，表示优化器现在使用了索引范围扫描，而不是全表扫描。这大大减少了需要扫描的行数。  
2、key列：对于users表，key从NULL变为idx\_user\_name\_age，表示优化器使用了新创建的覆盖索引。对于orders表，key仍然是user\_id，表示继续使用user_id索引。  
3、rows列：对于users表，rows从4减少到2，表示优化器估计只需要扫描2行，而不是原来的4行。这是因为age > 30的条件可以通过索引快速过滤。  
4、Extra列：对于users表，Extra是Using where,Using index，表示优化器使用了索引中的列进行过滤，并且只从索引中获取数据。

#### 5、进一步优化：使用EXISTS替代JOIN

虽然JOIN已经优化得很好，但在某些情况下，EXISTS可能比JOIN更高效，尤其是在子查询返回大量结果时。我们可以将查询改写为使用 EXISTS：  
**sql改写示例：**

    SELECT o.order_date, o.amount 
    FROM orders o 
    WHERE EXISTS (
        SELECT 1 
        FROM users u 
        WHERE u.user_id = o.user_id AND u.age > 30
    );

**运行结果：**  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3d1c082610234f9d92a9ccb5de4a067a.png)

通过这些优化手段，可以显著提高查询性能，减少I/O操作和CPU使用率。同时，使用EXPLAIN分析查询的执行计划，可以帮助你更好地理解优化器的行为，并找出潜在的性能瓶颈。  
**理解EXPLAIN输出：**

* id：查询的标识符，数值越大，优先级越高。
* select_type：查询的类型（如简单查询、子查询、联合查询等）。
* table：当前操作的表。
* type：访问类型（如 ALL、index、range、ref、eq_ref、const 等）。
* possible_keys：可能使用的索引。
* key：实际使用的索引。
* key_len：索引的长度。
* ref：与索引比较的列或常量。
* rows：估计需要扫描的行数。
* Extra：额外的信息（如是否使用临时表、是否进行排序等）。

**优化查询执行计划：**

* 避免全表扫描：尽量使用索引，减少扫描的行数。
* 减少索引扫描范围：通过合理的索引设计，缩小查询范围。
* 避免不必要的排序：尽量使用覆盖索引，避免回表查询。
* 优化JOIN顺序：调整表的连接顺序，减少中间结果集的大小。

### 三、性能调优

MySQL的性能优化是一个多维度的过程，涉及数据库设计、查询优化、服务器配置、硬件资源等多个方面。通过合理的优化，可以显著提升MySQL数据库的响应速度、吞吐量和稳定性。

#### 1、数据库设计优化

##### （1）、选择合适的数据类型

* 使用最小的数据类型：选择能够满足需求的最小数据类型，以减少存储空间和I/O操作。例如，如果一个整数列的最大值不会超过65,535，可以使用SMALLINT而不是INT。

* 避免使用大对象类型：尽量避免使用TEXT、BLOB等大对象类型，除非确实需要存储大量的文本或二进制数据。大对象会增加I/O开销，并且可能不适合缓存。

* 使用枚举（ENUM）和集合（SET）类型：对于有限的选项列表，可以考虑使用ENUM或SET类型，而不是使用VARCHAR或TEXT。这些类型在存储和检索时更高效。

##### （2）、规范化与反规范化

* 规范化：规范化是将数据分解为多个表，以减少冗余和提高数据一致性。虽然规范化可以提高数据的完整性和一致性，但它可能会增加连接操作的复杂性，导致查询变慢。

* 反规范化：反规范化是通过增加冗余来减少连接操作，从而提高查询性能。例如，可以在主表中存储一些来自关联表的常用字段，以减少JOIN操作。然而，反规范化可能会导致数据冗余和维护成本增加。

建议：根据实际需求权衡规范化和反规范化的优缺点。对于频繁读取但很少更新的数据，可以适当进行反规范化；而对于频繁更新的数据，建议保持规范化。

##### （3）、分区表

对于非常大的表，可以考虑使用分区表（Partitioning）。分区表将数据按某种规则（如日期、范围、列表等）分散到不同的物理存储区域，从而提高查询性能和管理效率。

**示例：**

    CREATE TABLE orders (
        order_id INT AUTO_INCREMENT PRIMARY KEY,
        user_id INT,
        order_date DATE,
        amount DECIMAL(10, 2)
    ) PARTITION BY RANGE (YEAR(order_date)) (
        PARTITION p2020 VALUES LESS THAN (2021),
        PARTITION p2021 VALUES LESS THAN (2022),
        PARTITION p2022 VALUES LESS THAN (2023)
    );

**优点：**

* 提高查询性能：分区表可以根据分区条件快速定位到所需的记录，减少全表扫描的开销。
* 简化数据维护：分区表可以更容易地进行数据归档、清理等操作。

##### （4）、索引设计

索引是提升查询性能的关键。合理的索引设计可以显著加快查询速度，但过多的索引也会增加写入操作的开销。因此，索引的设计需要权衡读写性能。

* 创建合适的索引：为查询条件列、连接条件列和排序分组的列创建索引。确保索引的选择性足够高，以减少扫描的行数。

* 覆盖索引：覆盖索引是指索引中包含了查询所需的所有列，这样查询可以直接从索引中获取数据，而不需要访问表的数据页。覆盖索引可以显著减少I/O操作，提升查询速度。

* 避免过度索引：虽然索引可以加速查询，但过多的索引会增加写入操作的开销。每次插入、更新或删除数据时，MySQL都需要维护索引，这会导致性能下降。因此，只创建必要的索引。

* 使用复合索引：对于多个条件组合的查询，可以考虑创建复合索引（Composite Index）。复合索引可以同时加速多个条件的查询。  
  **示例：**
  
    -- 创建单列索引
    CREATE INDEX idx_user_id ON users (user_id);
    -- 创建复合索引
    CREATE INDEX idx_user_age ON users (user_id, age);

#### 2、查询优化

##### （1）、避免使用SELECT *

SELECT *会返回表中的所有列，即使某些列并不需要。这不仅增加了I/O操作和网络传输开销，还可能导致无法使用覆盖索引。因此，建议显式列出你需要的列。

**示例：**

    -- 不推荐：返回所有列
    SELECT * FROM users WHERE age > 30;
    
    -- 推荐：只返回需要的列
    SELECT user_id, name, age FROM users WHERE age > 30;

##### （2）、使用EXPLAIN分析查询

EXPLAIN是MySQL提供的一个工具，用于分析查询的执行计划。通过EXPLAIN，你可以了解MySQL如何执行查询，包括是否使用了索引、扫描了多少行、是否有全表扫描等。

**示例：**

    EXPLAIN SELECT * FROM users WHERE age > 30;

**EXPLAIN的输出结果包含以下重要列：**

* id：查询的标识符。
* select_type：查询的类型。
* table：当前操作的表。
* type：访问类型（如 ALL、index、range、ref 等）。ALL表示全表扫描，ref表示通过索引查找。
* possible_keys：可能使用的索引。
* key：实际使用的索引。
* key_len：索引的长度。
* ref：与索引比较的列或常量。
* rows：估计需要扫描的行数。
* filtered：根据条件过滤后剩余的行数百分比。
* Extra：额外的信息（如Using where、Using index、Using temporary等）。

##### （3）、优化JOIN查询

JOIN操作是MySQL中常见的查询方式，但也可能是性能瓶颈。为了优化JOIN查询，建议遵循以下原则：

* 确保连接条件上有索引：为JOIN条件列创建索引，避免全表扫描。例如，在LEFT JOIN中，确保ON子句中的列上有索引。

* 使用适当的JOIN类型：根据查询的需求选择合适的JOIN类型。例如，INNER JOIN只返回匹配的记录，而LEFT JOIN返回左表中的所有记录，即使右表中没有匹配的记录。

* 避免嵌套子查询：嵌套子查询可能会导致性能问题，尤其是在子查询返回大量结果时。可以尝试使用JOIN替代嵌套子查询。

* 使用EXISTS替代IN：在某些情况下，EXISTS比IN更高效，尤其是在子查询返回大量结果时。  
  **示例：**
  
    -- 使用 IN 子查询
    SELECT * FROM orders WHERE user_id IN (SELECT user_id FROM users WHERE age > 30);
    -- 使用 EXISTS 替代 IN
    SELECT * FROM orders o WHERE EXISTS (SELECT 1 FROM users u WHERE u.user_id = o.user_id AND u.age > 30);

##### （4）、分页查询优化

分页查询通常使用LIMIT和OFFSET，但随着OFFSET的增加，查询性能会显著下降。为了避免这个问题，可以使用主键或唯一列进行分页，或者使用游标技术。

**示例：**

    -- 使用OFFSET 进行分页（不推荐）
    SELECT * FROM orders ORDER BY order_id LIMIT 10 OFFSET 9000;
    -- 使用主键进行分页（推荐）
    SELECT * FROM orders WHERE order_id > 9000 ORDER BY order_id LIMIT 10;

##### （5）、使用UNION ALL替代OR

在某些情况下，OR条件可能会导致MySQL无法使用索引，从而导致全表扫描。可以尝试使用UNION ALL替代OR，特别是在OR条件涉及不同列时。

**示例：**

    -- 使用OR条件
    SELECT * FROM users WHERE name = 'Alice' OR email = 'alice@example.com';
    
    -- 使用UNION ALL替代OR
    (SELECT * FROM users WHERE name = 'Alice')
    UNION ALL
    (SELECT * FROM users WHERE email = 'alice@example.com');

#### 3、服务器配置优化

##### （1）、调整缓冲区大小

MySQL提供了多种缓冲区来缓存数据和索引，合理调整缓冲区大小可以显著提升性能。常用的缓冲区包括：

* innodb\_buffer\_pool_size：InnoDB缓冲池的大小，用于缓存表数据和索引。建议将该参数设置为服务器内存的70%-80%，以确保足够的缓存空间。

* query\_cache\_size：查询缓存的大小，用于缓存查询结果。虽然查询缓存可以加速重复查询，但在高并发场景下可能会成为性能瓶颈。建议禁用查询缓存（即：query\_cache\_size = 0），并使用应用层缓存（如Redis、Memcached）替代。

* tmp\_table\_size和max\_heap\_table_size：临时表的最大大小。当查询需要创建临时表时，MySQL会优先使用内存中的临时表，但如果临时表超过这两个参数的限制，MySQL会将其转换为磁盘上的临时表，导致性能下降。建议根据实际情况调整这两个参数的大小。

##### （2）、启用慢查询日志

慢查询日志可以帮助你识别执行时间较长的查询，并采取相应的优化措施。

**可以通过以下参数启用慢查询日志：**

* slow\_query\_log：启用或禁用慢查询日志。
* long\_query\_time：设置慢查询的时间阈值（单位为秒）。超过这个时间的查询会被记录到慢查询日志中。
* log\_queries\_not\_using\_indexes：是否记录不使用索引的查询。

**配置示例：**

    [mysqld]
    slow_query_log = 1
    slow_query_log_file = /var/log/mysql/slow-query.log
    long_query_time = 2
    log_queries_not_using_indexes = 1

##### （3）、调整InnoDB配置

InnoDB是MySQL的默认存储引擎，合理的InnoDB配置可以显著提升性能。

**常用的InnoDB参数包括：**

* innodb\_buffer\_pool_size：如前所述，建议将该参数设置为服务器内存的70%-80%。
* innodb\_flush\_method：设置InnoDB的刷新方法。O_DIRECT可以避免双倍缓冲（即操作系统缓存和InnoDB缓存同时存在），减少I/O开销。
* innodb\_flush\_log\_at\_trx_commit：控制事务提交时的日志刷新行为。1表示每次提交时都刷新日志，保证数据的安全性；2表示每秒刷新一次日志，适合对性能要求较高的场景。
* innodb\_io\_capacity：设置磁盘I/O的最大容量。根据你的磁盘性能调整该参数，以充分利用磁盘带宽。

#### 4、硬件资源优化

##### （1）、选择合适的硬件

* CPU：选择多核CPU，以支持多线程并发处理。MySQL是多线程应用程序，能够充分利用多核CPU的优势。
* 内存：增加内存可以显著提升MySQL的性能，特别是对于InnoDB缓冲池和其他缓冲区。建议将内存的70%-80%用于InnoDB缓冲池。
* 磁盘：使用SSD（固态硬盘）代替传统HDD（机械硬盘），以提高I/O性能。SSD的随机读写速度远高于HDD，特别适合InnoDB的小块I/O操作。
* 网络：确保数据库服务器和应用服务器之间的网络带宽充足，避免网络延迟影响性能。

##### （2）、使用RAID

RAID（独立磁盘冗余阵列）可以提高磁盘的读写性能和数据安全性。

**常用的RAID级别包括：**

* RAID 0：条带化，提供最高的读写性能，但没有冗余，任何一块磁盘故障都会导致数据丢失。
* RAID 1：镜像，提供数据冗余，但读写性能较低。
* RAID 10：结合了RAID 0和RAID 1的优点，既有条带化的高性能，又有镜像的冗余性，适合MySQL数据库。

##### （3）、使用分布式数据库

对于非常大的数据集或高并发场景，可以考虑使用分布式数据库（如MySQL Cluster、Galera Cluster、TiDB等）。分布式数据库可以将数据分布到多个节点上，提升系统的扩展性和容错能力。

#### 5、监控与调优

##### （1）、使用性能监控工具

定期监控MySQL的性能指标，及时发现潜在的问题。

**常用的性能监控工具包括：**

* SHOW STATUS和SHOW VARIABLES：查看MySQL的运行状态和配置参数。
* SHOW PROCESSLIST：查看当前正在执行的查询，帮助你发现长时间运行的查询。
* Performance Schema：MySQL内置的性能监控工具，提供了详细的性能统计信息。
* Percona Monitoring and Management (PMM)：Percona提供的开源监控工具，支持MySQL、MongoDB等数据库的性能监控。
* Prometheus + Grafana：开源的监控和可视化工具，可以与MySQL结合使用，提供实时的性能监控和报警功能。

##### （2）、定期分析慢查询日志

慢查询日志是发现性能瓶颈的重要工具。可以使用mysqldumpslow或pt-query-digest等工具解析慢查询日志，找出最耗时的查询，并采取相应的优化措施。

##### （3）、使用EXPLAIN ANALYZE

MySQL 8.0引入了EXPLAIN ANALYZE命令，它不仅可以显示查询的执行计划，还可以实际执行查询并返回详细的性能统计信息。这对于分析复杂的查询非常有用。

**示例：**

    EXPLAIN ANALYZE SELECT * FROM users WHERE age > 30;

#### 6、Mysql性能优化总结

MySQL性能优化是一个持续的过程，涉及多个方面的技术和策略。通过合理的数据库设计、查询优化、服务器配置和硬件资源优化，可以显著提升MySQL的性能和稳定性。

**以下是关键的优化建议：**  
（1）、数据库设计：选择合适的数据类型，规范化与反规范化相结合，使用分区表和索引设计。  
（2）、查询优化：避免使用SELECT *，使用EXPLAIN分析查询，优化JOIN和分页查询。  
（3）、服务器配置：调整缓冲区大小，启用慢查询日志，优化InnoDB配置。  
（4）、硬件资源：选择合适的硬件，使用SSD和RAID，考虑分布式数据库。  
（5）、监控与调优：使用性能监控工具，定期分析慢查询日志，使用EXPLAIN ANALYZE深入分析查询性能。

### 四、慢日志分析

MySQL的慢查询日志（Slow Query Log）是用于记录执行时间超过指定阈值的SQL查询的日志文件。通过分析慢查询日志，可以发现性能瓶颈并优化查询。

#### 1、启用慢查询日志

##### （1）、全局配置文件

**全局配置文件中启用：**  
要永久启用慢查询日志，可以在MySQL的全局配置文件my.cnf或my.ini中进行设置。

**配置示例：**

    [mysqld]
    # 启用慢查询日志
    slow_query_log = 1
    
    # 指定慢查询日志文件路径（可选）
    slow_query_log_file = /var/log/mysql/slow-query.log
    
    # 设置慢查询的时间阈值（单位：秒，默认为10秒）
    long_query_time = 2
    
    # 是否记录不使用索引的查询（可选）
    log_queries_not_using_indexes = 1
    
    # 是否记录管理员命令（如ALTER TABLE、CREATE INDEX等，可选）
    log_slow_admin_statements = 1
    
    # 是否记录所有查询（包括快速查询，可选）
    log_slow_slave_statements = 1

**解释：**

* slow\_query\_log：启用或禁用慢查询日志。1表示启用，0表示禁用。
* slow\_query\_log_file：指定慢查询日志文件的路径。如果不指定，默认会存储在数据目录下，文件名为hostname-slow.log。
* long\_query\_time：设置查询执行时间的阈值（单位为秒）。超过这个时间的查询会被记录到慢查询日志中。默认值为10秒，建议根据实际情况调整。
* log\_queries\_not\_using\_indexes：是否记录不使用索引的查询。启用后，即使查询执行时间很短，但如果没有使用索引的查询也会被记录。
* log\_slow\_admin_statements：是否记录管理员命令（如ALTER TABLE、CREATE INDEX等）。这些命令通常是耗时操作，记录它们有助于分析数据库的整体性能。
* log\_slow\_slave_statements：是否记录从库上的慢查询。这对于主从复制环境中的性能分析非常有用。

##### （2）、动态启用慢查询日志

如果你不想修改配置文件，可以通过动态设置系统变量来临时启用慢查询日志。这样可以在不重启MySQL服务的情况下启用或禁用慢查询日志。

**sql示例：**

    -- 启用慢查询日志
    SET GLOBAL slow_query_log = 1;
    
    -- 设置慢查询日志文件路径
    SET GLOBAL slow_query_log_file = '/var/log/mysql/slow-query.log';
    
    -- 设置慢查询的时间阈值（单位：秒）
    SET GLOBAL long_query_time = 2;
    
    -- 是否记录不使用索引的查询
    SET GLOBAL log_queries_not_using_indexes = 1;

**注意：**  
动态设置的参数只在当前会话或服务器运行期间有效，重启MySQL服务后会恢复为默认值。因此，如果需要永久生效，建议修改配置文件。

#### 2、查看慢查询日志

##### （1）、直接查看日志文件

慢查询日志文件通常是一个文本文件，可以直接使用文本编辑器（如vi、nano）或命令行工具（如cat、less）查看。

**例如：**  
使用 less 查看慢查询日志  
**命令示例：**

    less /var/log/mysql/slow-query.log

使用 tail 查看最新的慢查询  
**命令示例：**

    tail -f /var/log/mysql/slow-query.log

##### （2）、使用mysqldumpslow工具

MySQL提供了一个内置工具mysqldumpslow，用于解析和汇总慢查询日志。它可以帮助你快速找到最耗时的查询，并统计每个查询的出现次数和平均执行时间。

**常用命令示例：**  
显示慢日志slow-query.log中前 10 条最耗时的查询

    mysqldumpslow -s t -n 10 /var/log/mysql/slow-query.log

显示出现次数最多的 10 条查询

    mysqldumpslow -s c -n 10 /var/log/mysql/slow-query.log

显示按平均时间排序的 10 条查询（对相同查询sql，可能第1次10秒，第2次2秒，这中场景下，取平均时间更可靠一点）

    mysqldumpslow -s at -n 10 /var/log/mysql/slow-query.log

显示包含特定关键词的查询（例如 ‘users’ 表）

    mysqldumpslow -g 'users' /var/log/mysql/slow-query.log

**解释：**

* -s：指定排序方式。常见的选项有：
  * t：按总时间排序。
  * c：按查询次数排序。
  * at：按平均时间排序。
  * l：按锁定时间排序。
  * r：按返回的行数排序。
* -n：限制输出的查询数量。
* -g：使用正则表达式过滤特定的查询。

##### （3）、使用pt-query-digest工具

pt-query-digest是Percona Toolkit中的一个强大工具，用于分析慢查询日志。相比于mysqldumpslow，pt-query-digest提供了更详细的统计信息和更好的可视化效果。它可以解析MySQL的慢查询日志、通用查询日志（General Query Log）以及二进制日志（Binary Log）。

**安装Percona Toolkit示例：**  
Ubuntu/Debian环境：

    sudo apt-get install percona-toolkit

**CentOS/RHEL环境：**

    sudo yum install percona-toolkit

**常用命令：**

     分析慢查询日志
    pt-query-digest /var/log/mysql/slow-query.log
    
     分析二进制日志
    pt-query-digest --type binlog /path/to/binlog.000001
    
     分析通用查询日志
    pt-query-digest --type genlog /path/to/general-query.log

**解释：**  
pt-query-digest会生成详细的报告，包括：

* 查询的执行频率。
* 查询的平均、最大和最小执行时间。
* 查询的锁定时间。
* 查询返回的行数。
* 查询的I/O和CPU使用情况。
* 查询的执行计划（如果有）。

#### 3、分析慢查询日志

##### （1）、识别问题查询

通过查看慢查询日志，你可以识别出哪些查询执行时间过长，或者哪些查询没有使用索引。

**以下是常见的问题查询类型：**

* 全表扫描（Table Scan）：查询没有使用索引，导致MySQL需要扫描整个表。这种查询通常会导致I/O操作增加，尤其是在大表上。  
  解决方法：为查询条件列创建合适的索引，避免全表扫描。

* 未使用索引的查询：即使表上有索引，某些查询可能仍然没有使用索引。这可能是由于查询条件不符合索引的设计，或者查询涉及多个表的连接操作。  
  解决方法：检查查询的EXPLAIN执行计划，确保查询能够正确使用索引。如果无法使用现有索引，考虑创建新的索引或调整查询逻辑。

* 复杂的子查询或连接操作：涉及多个表的连接操作或嵌套子查询可能会导致查询性能下降，尤其是在没有适当索引的情况下。  
  解决方法：优化查询结构，尽量使用JOIN替代嵌套子查询，并确保连接条件上有适当的索引。

* 大量返回行数的查询：某些查询可能返回大量的行，导致网络传输和内存占用增加。  
  解决方法：限制返回的行数，使用分页查询（如LIMIT和OFFSET），或者只选择需要的列，避免不必要的数据传输。

##### （2）、使用EXPLAIN分析查询

对于每个慢查询，建议使用EXPLAIN来分析其执行计划。EXPLAIN可以帮助你了解MySQL如何执行查询，包括是否使用了索引、扫描了多少行、是否有全表扫描等。

**示例：**

    EXPLAIN SELECT * FROM users WHERE age > 30;

\*\* EXPLAIN的输出结果包含以下重要列：**

* id：查询的标识符。相同的id表示查询属于同一个查询块。
* select_type：查询的类型（如SIMPLE、PRIMARY、SUBQUERY等）。
* table：当前操作的表。
* partitions：涉及的分区（如果有分区表）。
* type：访问类型（如ALL、index、range、ref等）。ALL 表示全表扫描，ref表示通过索引查找。
* possible_keys：可能使用的索引。
* key：实际使用的索引。
* key_len：索引的长度。
* ref：与索引比较的列或常量。
* rows：估计需要扫描的行数。
* filtered：根据条件过滤后剩余的行数百分比。
* Extra：额外的信息（如Using where、Using index、Using temporary等）。  
  通过EXPLAIN，你可以发现查询是否存在性能问题，并采取相应的优化措施。

##### （3）、使用SHOW PROFILES和SHOW PROFILE

MySQL还提供了SHOW PROFILES和SHOW PROFILE命令，用于查看单个查询的详细性能信息。SHOW PROFILES可以列出最近执行的所有查询及其执行时间，而SHOW PROFILE可以显示某个查询的具体性能指标。

**查看当前MySQL是否支持profile操作：**

    SELECT @@have_profiling ;

**运行结果：**  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0bc43d40cb454b15ba4244aaa6fbfded.png)  
YES标识数据库支持profile操作。

**查看mysql是否开启profile：**

    SELECT @@profiling ;

**运行结果：**  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/87b41774373f47139691305e569ee2b8.png)  
1标识开启，0为未开启。

**开启或关闭profile：**  
开启profile

    SET profiling = 1;

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/d5f6510d05884969b9f947ecf42b5281.png)

**profiles查看最近执行的查询及其执行时间：**  
可以查看sql的queryId和时间等信息。  
**示例：**

    select * from sys_user where id = '2a01983a00d6533524f84bffcf07fa58';
    select * from sys_user where name = '李四';
    select id,name,GENDER from sys_user where name = '李四';
    show profiles;      // 查看profile的queryId等

**运行结果：**  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6f2d05725ce347f483b35a16de6a351a.png)  
解释：  
profiles可以帮我们看到sql以及queryId和耗时等信息，可以使用profile语句，对queryId的查询进一步分析。

**profile查看某个查询的详细性能信息：**  
通过上诉我们可以查询到sql的queryId，之后可以进一步分析消耗。

    show profile for query 6;
    show profile cpu for query 6;

**运行结果：**  
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/fd0fa50cd9bf446c9253fce2acf6805e.png)  
**解释：**  
SHOW PROFILE 的输出结果包含以下性能指标：（Duration为某项指标总耗时，后面两个为user耗时和system耗时）

* query end：查询结束时间。
* sending data：发送数据的时间。
* sorting result：排序结果的时间。
* executing：执行查询的时间。
* statistics：获取统计信息的时间。
* parsing：解析查询的时间。
* opening tables：打开表的时间。
* locking tables：锁定表的时间。

#### 4、优化慢查询

一旦识别出慢查询，接下来就是优化它们。  
**常见的优化手段包括：**  
1、创建合适的索引：为查询条件列创建索引，避免全表扫描。确保索引的选择性足够高，以减少扫描的行数。  
2、优化查询语句：避免使用SELECT *，只选择需要的列。使用JOIN替代嵌套子查询，简化查询结构。  
3、使用覆盖索引：确保查询所需的所有列都在索引中，避免回表操作。  
4、优化表结构：选择合适的数据类型，避免使用过大的列（如TEXT、BLOB）。对于大表，考虑使用分区表或水平拆分表。  
5、使用缓存：对于不经常变化的数据，可以使用Redis、Memcached等缓存系统来减少对数据库的频繁查询。  
6、调整数据库配置：优化MySQL的缓冲区大小、查询缓存、并行查询等配置参数，提升整体性能。

#### 5、慢日志总结

MySQL的慢查询日志是分析和优化查询性能的重要工具。通过启用慢查询日志，你可以记录执行时间较长的查询，并使用mysqldumpslow或pt-query-digest等工具进行分析。结合 EXPLAIN和SHOW PROFILES，你可以深入了解查询的执行计划和性能瓶颈，从而采取相应的优化措施。  
常见的优化手段包括创建合适的索引、优化查询语句、使用覆盖索引、优化表结构等。通过这些方法，可以显著提高查询性能，减少资源消耗，并提升系统的响应速度。  
如果你发现某些查询频繁出现在慢查询日志中，建议定期对其进行优化，并监控其性能变化。此外，定期清理不再需要的慢查询日志文件，以避免日志文件过大影响系统性能。

# MySQL的MVCC

### 摘要

在当今高度并发的数据库环境中，有效的并发控制是至关重要的。MVCC是MySQL中被广泛采用的并发控制机制，它通过版本管理来实现事务的隔离性，允许读写操作同时进行，提高数据库的并发性能和响应能力。

本文将深入解析MVCC机制的原理，帮助读者更好地理解和应用这一关键技术。

### MVCC 介绍

**MVCC，全称 Multi-Version Concurrency Control，即多版本并发控制**

MVCC的目的主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁。

这里的多版本指的是数据库中同时存在多个版本的数据，并不是整个数据库的多个版本，而是某一条记录的多个版本同时存在。

**并发控制的挑战**

在数据库系统中，同时执行的事务可能涉及相同的数据，因此需要一种机制来保证数据的一致性，传统的锁机制可以实现并发控制，但会导致阻塞和死锁等问题。

**MVCC的优点**

MVCC机制具有以下优点：

* 提高并发性能：读操作不会阻塞写操作，写操作也不会阻塞读操作，有效地提高数据库的并发性能。
* 降低死锁风险：由于无需使用显式锁来进行并发控制，MVCC可以降低死锁的风险。

### 当前读和快照读

在讲解MVCC原理之前，我们先来了解一下，当前读和快照读。

**当前读**

在MySQL中，当前读是一种读取数据的操作方式，它可以直接读取最新的数据版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。MySQL提供了两种实现当前读的机制：

* 一致性读（Consistent Read）：
  * 默认隔离级别下（可重复读），MySQL使用一致性读来实现当前读。
  * 在事务开始时，MySQL会创建一个一致性视图（Consistent View），该视图反映了事务开始时刻数据库的快照。
  * 在事务执行期间，无论其他事务对数据进行了何种修改，事务始终使用一致性视图来读取数据。
  * 这样可以保证在同一个事务内多次查询返回的结果是一致的，从而实现了当前读。
* 锁定读（Locking Read）：
  * 锁定读是一种特殊情况下的当前读方式，在某些场景下使用。
  * 当使用锁定读时，MySQL会在执行读取操作前获取共享锁或排他锁，以确保数据的一致性。
  * 共享锁（Shared Lock）允许多个事务同时读取同一数据，而排他锁（Exclusive Lock）则阻止其他事务读取或写入该数据。
  * 锁定读适用于需要严格控制并发访问的场景，但由于加锁带来的性能开销较大，建议仅在必要时使用。

下面列举的这些语法都是当前读：

SELECT ... LOCK IN SHARE MODE

SELECT ... FOR UPDATE

UPDATE

DELETE

INSERT

当前读实际上是一种加锁的操作，是悲观锁的实现。

**快照读**

快照读是在读取数据时读取一个一致性视图中的数据，MySQL使用 MVCC 机制来支持快照读。

具体而言，每个事务在开始时会创建一个一致性视图（Consistent View），该视图反映了事务开始时刻数据库的快照。这个一致性视图会记录当前事务开始时已经提交的数据版本。

当执行查询操作时，MySQL会根据事务的一致性视图来决定可见的数据版本。只有那些在事务开始之前已经提交的数据版本才是可见的，未提交的数据或在事务开始后修改的数据则对当前事务不可见。

像不加锁的 select 操作就是快照读，即不加锁的非阻塞读。

快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本。

**注意：快照读的前提是隔离级别不是串行级别，在串行级别下，事务之间完全串行执行，快照读会退化为当前读**

MVCC主要就是为了实现读-写冲突不加锁，而这个读指的就是快照读，是乐观锁的实现。

### MVCC 原理解析

#### 隐式字段

MySQL中的行数据，除了我们肉眼能看到的字段之外，其实还包含了一些隐藏字段，它们在内部使用，默认情况下不会显示给用户。

| 字段            | 含义                                                                         |
|:------------- | -------------------------------------------------------------------------- |
| DB\_ROW\_ID   | 隐含的自增ID（隐藏主键），用于唯一标识表中的每一行数据，如果数据表没有主键，InnoDB会自动以DB\_ROW\_ID产生一个聚簇索引。      |
| DB\_TRX\_ID   | 该字段存储了当前行数据所属的事务ID。每个事务在数据库中都有一个唯一的事务ID。通过 DB\_TRX\_ID 字段，可以追踪行数据和事务的所属关系。 |
| DB\_ROLL\_PTR | 该字段存储了回滚指针（Roll Pointer），它指向用于回滚事务的Undo日志记录。                               |

#### Undo Log

上文提到了 Undo 日志，这个 Undo 日志是 MVCC 能够得以实现的核心所在。

Undo日志（Undo Log）是MySQL中的一种重要的事务日志，Undo日志的作用主要有两个方面：

* **事务回滚**：当事务需要回滚时，MySQL可以通过Undo日志中的旧值将数据还原到事务开始之前的状态，保证了事务回滚的一致性。
* **MVCC实现**：MVCC 是InnoDB存储引擎的核心特性之一。通过使用Undo日志，MySQL可以为每个事务提供独立的事务视图，使得事务读取数据时能看到一致且符合隔离级别要求的数据版本。

**在InnoDB存储引擎中，Undo日志分为两种：插入（insert）Undo日志 和 更新（update）Undo日志**

* insert undo log：插入Undo日志是指在插入操作中生成的Undo日志。由于插入操作的记录只对当前事务可见，对其他事务不可见，因此在事务提交后可以直接删除，无需进行purge操作。
* update undo log：更新Undo日志是指在更新或删除操作中生成的Undo日志。更新Undo日志可能需要提供MVCC机制，因此不能在事务提交时就立即删除。相反，它们会在提交时放入Undo日志链表中，并等待purge线程进行最终的删除。删除操作只是设置一下老记录的 DELETED\_BIT，并不真正将过时的记录删除，为了节省磁盘空间，InnoDB有专门的purge线程来清理 DELETED\_BIT 为true的记录。

注意：由于查询操作（SELECT）并不会修改任何记录，所以在查询操作执行时，并不需要记录相应的 undo log 。

**不同事务或者相同事务对同一记录行的修改，会使该记录行的 undo log 成为一条链表，链首就是最新的记录，链尾就是最早的旧记录**

举个例子，比如有个事务A插入了一条新记录：insert into user(id, name) values(1, "小明')

![](https://developer.qcloudimg.com/http-save/yehe-3763514/195364fecfb201bfe06cf75afdb77057.png)

现在来了一个事务B对该记录的name做出了修改，改为 "小王"。

在事务B修改该行数据时，数据库会先对该行加排他锁，然后把该行数据拷贝到 undo log 中作为旧记录，即在 undo log 中有当前行的拷贝副本.

拷贝完毕后，修改该行name为 "小王，并且修改隐藏字段的事务ID为当前事务B的ID, 并将回滚指针指向拷贝到 undo log 的副本记录，即表示我的上一个版本就是它，事务提交后，释放锁。

![](https://developer.qcloudimg.com/http-save/yehe-3763514/bfa9804682a31efe7ef92442e107fc25.png)

此时又来了个事务C修改同一个记录，将name修改为 "小红"。

在事务C修改该行数据时，数据库也先为该行加锁，然后把该行数据拷贝到 undo log 中，作为旧记录，发现该行记录已经有 undo log 了，那么最新的旧数据作为链表的表头，插在该行记录的 undo log 最前面，如下图：

![](https://developer.qcloudimg.com/http-save/yehe-3763514/0b4479a7b3b1534e914bf821703744cf.png)

关于 DB\_ROLL\_PTR 与 Undo日志 的配合工作，具体流程如下：

1. 在更新或删除操作之前，MySQL会将旧值写入Undo日志中。
2. 当事务需要回滚时，MySQL会根据事务的Undo日志记录，通过 DB\_ROLL\_PTR 找到对应的Undo日志。
3. 根据Undo日志中记录的旧值，MySQL将旧值恢复到相应的数据行中，实现数据的回滚操作。

比方说现在想回滚到事务B，name值为 "小王" 的时候，只需通过 DB\_ROLL\_PTR 顺着列表找到对应的 Undo日志，将旧值恢复到数据行即可。

![](https://developer.qcloudimg.com/http-save/yehe-3763514/e136865046b5e7c76d162f60edca8d48.png)

通过 DB\_ROLL\_PTR 和 Undo日志 的配合工作，MySQL能够有效地管理事务的一致性和隔离性。Undo日志的使用也使得MySQL能够支持MVCC，从而提供了高并发环境下的读取一致性和事务隔离性。

#### 版本链

在MVCC中，对于每次更新操作，旧值会被保存到一条undo日志中，即使它是该记录的旧版本。随着更新次数的增加，所有的版本都会通过roll_pointer属性连接成一个链表，称之为版本链。

版本链的头节点代表当前记录的最新值。此外，每个版本还包含生成该版本的事务ID。

#### Read View

**一致性视图，全称 Read View ，是用来判断版本链中的哪个版本对当前事务是可见的**

Read View 说白了就是事务进行快照读操作时候生成的读视图（Read View），在该事务执行快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID（每个事务开启时，都会被分配一个ID，这个ID是递增的）。

这里有一点要注意一下：**Read View只针对 RC (READ COMMITED, 已提交读/不可重复读) 和 RR (REPEATABLE READ, 可重复读) 级别**

Read Uncommitted（RU）和 Serializable（串行化）是两个特殊的隔离级别，它们不需要使用 Read View 的主要原因是：

* Read Uncommitted（RU）隔离级别：在 RU 隔离级别下，事务可以读取其他事务尚未提交的数据，即脏读。这意味着不需要通过 Read View 来限制访问范围，事务可以自由地读取其他事务的未提交数据。由于没有对可见性进行严格控制，因此不需要创建或使用 Read View。
* Serializable（串行化）隔离级别：在 Serializable 隔离级别下，事务具有最高的隔离性，确保每次读取都能看到一致的快照。为了实现这种隔离级别，MySQL使用锁机制来保证事务之间的串行执行。由于事务按顺序执行，并且不允许并发操作，所以不需要使用 Read View 进行可见性判断。

Read Uncommitted 和 Serializable 隔离级别下的事务规则不涉及基于 Read View 的可见性判断。RU 允许脏读，而 Serializable 则通过锁机制保证串行执行。因此，在这两个隔离级别下，不需要创建或使用 Read View。

#### Read View 可见性原则

Read View 遵循一个可见性原则，将要被修改的数据的 DB\_TRX\_ID 取出来，与系统当前其他活跃事务的ID去对比。

如果 DB\_TRX\_ID 跟 Read View 的属性做了某些比较，不符合可见性，那就通过 DB\_ROLL\_PTR 回滚指针去取出 Undo Log 中的 DB\_TRX\_ID 再比较。

即遍历链表的 DB\_TRX\_ID （从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的 DB\_TRX\_ID，那么这个 DB\_TRX\_ID 所在的记录就是当前事务能看见的最新老版本。

Read View 会维护以下几个字段：

| 字段                 | 含义                                                                                                                      |
| ------------------ | ----------------------------------------------------------------------------------------------------------------------- |
| m_ids              | Read View 创建时其他未提交的活跃事务 ID 列表。创建 Read View时，将当前未提交事务 ID 记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。m_ids 不包括当前事务自己和已提交的事务（正在内存中）。 |
| m\_creator\_trx_id | 创建该 Read View 的事务 ID。                                                                                                   |
| m\_low\_limit_id   | 目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的数据版本均不可见。                                                                    |
| m\_up\_limit_id    | 活跃事务列表 m\_ids 中最小的事务 ID，如果 m\_ids 为空，则 m\_low\_limit\_id为m\_up\_limit\_id 。小于这个 ID 的数据版本均可见。                            |

Read View 可见性具体判断如下：

1. 如果被访问版本的 `DB_TRX_ID` 属性值与 Read View 中的 `m_creator_trx_id` 值相同，表示当前事务正在访问自己所修改的记录，因此该版本可以被当前事务访问。
2. 如果被访问版本的 `DB_TRX_ID` 属性值小于 Read View 中的 `m_up_limit_id` 值，说明生成该版本的事务在当前事务生成 Read View 之前已经提交，因此该版本可以被当前事务访问。
3. 如果被访问版本的 `DB_TRX_ID` 属性值大于或等于 Read View 中的 `m_low_limit_id` 值，说明生成该版本的事务在当前事务生成 Read View 之后才提交，因此该版本不能被当前事务访问。
4. 如果被访问版本的 `DB_TRX_ID` 属性值位于 Read View 的 `m_up_limit_id` 和 `m_low_limit_id` 之间（包括边界），则需要进一步检查 `DB_TRX_ID` 是否在`m_ids` 列表中。如果在列表中，说明在创建ReadView时生成该版本的事务仍处于活跃状态，因此该版本不能被访问；如果不在列表中，说明在创建 Read View 时生成该版本的事务已经提交，因此该版本可以被访问。

事务可见性示意图：

![](https://developer.qcloudimg.com/http-save/yehe-3763514/12b22199c169fc0518b5a6b56e4f986a.png)

### RC 和 RR 下的 Read View

RC 和 RR 下生成 `Read View` 的时机是有所差异的：

* **RC**：每次 SELECT 数据前都生成一个ReadView。
* **RR**：只在第一次读取数据时生成一个ReadView，后面会复用第一次生成的。

正因为RC 和 RR生成 Read View 的时机不同，导致两个级别下看到的数据会不一致。

举例说明，假设数据初始状态如下：

![](https://developer.qcloudimg.com/http-save/yehe-3763514/ac89a07ad791a01d3865d790f72029ae.png)

有 A，B，C 三个事务，执行顺序如下：

|     | 事务A（事务ID: 100）                       | 事务B（事务ID: 200）                       | 事务C（事务ID: 300）                  |
| --- | ------------------------------------ | ------------------------------------ | ------------------------------- |
| T1  | begin                                |                                      |                                 |
| T2  |                                      | begin                                | begin                           |
| T3  | update user set name="小王" where id=1 |                                      |                                 |
| T4  | update user set name="小红" where id=1 |                                      | select * from user where id = 1 |
| T5  | commit                               | update user set name="小黑" where id=1 |                                 |
| T6  |                                      | update user set name="小白" where id=1 | select * from user where id = 1 |
| T7  |                                      | commit                               |                                 |
| T8  |                                      |                                      | select * from user where id = 1 |
| T9  |                                      |                                      | commit                          |
| T10 |                                      |                                      |                                 |

#### RC 下的 Read View

**T4时刻**

我们来看 T4 时刻的情况，此时 事务A 和 事务B 都还没提交，所以活跃的事务ID，即 `m_ids` 为：\[100，200\]，四个字段的值分别如下：

| 字段               | 值         |
| ---------------- | --------- |
| m_ids            | [100，200] |
| m_creator_trx_id | 300       |
| m_low_limit_id   | 400       |
| m_up_limit_id    | 100       |

T4时刻的版本链如下：

![](https://developer.qcloudimg.com/http-save/yehe-3763514/910ae42c0ebc4c99e972bbef98e31d8b.png)

依据我们之前说的可见性原则，事务C最终看到的应该是 `name = "小明"` 的数据，理由如下：

最新记录的 `DB_TRX_ID` 为 100，既不小于 `m_up_limit_id`，也不大于 `m_low_limit_id`，也不等于 `m_creator_trx_id`。

落在了黄区：

![](https://developer.qcloudimg.com/http-save/yehe-3763514/12b22199c169fc0518b5a6b56e4f986a.png)

`DB_TRX_ID` 存在于 `m_ids` 列表中，故不可见，顺着版本链继续往下。

根据 `DB_ROLL_PTR` 找到 `undo log` 中的前一版本记录，前一条记录的 `DB_TRX_ID` 还是 100，还是不可见，继续往下。

继续找前一条 `DB_TRX_ID`为 1，满足 1 < `m_up_limit_id`，可见，所以事务C 查询到数据为 `name = "小明"` 。

**T6时刻**

T6时候的版本链如下：

![](https://developer.qcloudimg.com/http-save/yehe-3763514/b2a91ba9a5f9644b423db6519c891807.png)

T6时刻，会再次生成新的 Read View，四个字段的值分别如下：

| 字段               | 值     |
| ---------------- | ----- |
| m_ids            | [200] |
| m_creator_trx_id | 300   |
| m_low_limit_id   | 400   |
| m_up_limit_id    | 200   |

根据可见性原则，最终T6时刻事务C 查询到数据为 `name = "小红"` 。

**T8时刻**

T8时刻的版本链和T6时刻是一致的，不同的是 Read View，因为T8时刻会再生成一个 Read View，四个字段的值分别如下：

| 字段               | 值   |
| ---------------- | --- |
| m_ids            | []  |
| m_creator_trx_id | 300 |
| m_low_limit_id   | 400 |
| m_up_limit_id    | 400 |

根据可见性原则，最终T8时刻事务C 查询到数据为 `name = "小白"` 。

总结一下，事务C在 RC 级别下各个时刻看到的数据如下：

| 时刻  | name |
| --- | ---- |
| T4  | 小明   |
| T6  | 小红   |
| T8  | 小白   |

下面我们来看看，RR 级别下的表现是如何的。

#### RR 下的 Read View

（RR 的版本链和 RC 的版本链是一致的，区别在于 Read View）

**T4时刻**

T4 时刻的情况，和 R C的情况是一致的：

| 字段               | 值         |
| ---------------- | --------- |
| m_ids            | [100，200] |
| m_creator_trx_id | 300       |
| m_low_limit_id   | 400       |
| m_up_limit_id    | 100       |

根据可见性原则，最终T4时刻事务C 查询到数据为 `name = "小明"` ，和 RC 的T4时刻是一致的。

**T6时刻**

RR 级别会复用 Read View，所以T6时刻也是：

| 字段               | 值         |
| ---------------- | --------- |
| m_ids            | [100，200] |
| m_creator_trx_id | 300       |
| m_low_limit_id   | 400       |
| m_up_limit_id    | 100       |

根据可见性原则，T6时刻我们发现事务C查询到的数据还是 `name = "小明"` 。

继续看T8时刻。

**T8时刻**

T8时刻继续复用先前的 Read View。

根据可见性原则，T8时刻事务C查询到的数据依旧是 `name = "小明"` 。

#### 小结

我们将事务C在 RC 和 RR 级别下看到的数据，放到一块来对比下：

| 时刻  | RC  | RR  |
| --- | --- | --- |
| T4  | 小明  | 小明  |
| T6  | 小红  | 小明  |
| T8  | 小白  | 小明  |

可以看出二者由于生成 Read View 的时机不同，导致在各个时刻看到的数据会存在差异。

回过头来看 RC 和 RR 隔离级别的定义，会有种恍然大悟的感觉：

* 读已提交（Read Committed）：事务只能读取到已经提交的数据。
* 可重复读（Repeatable Read）：事务在整个事务期间保持一致的快照视图，不受其他事务的影响。

**总之在 RC 隔离级别下，每个快照读都会生成并获取最新的 Read View；而在 RR 隔离级别下，则是只在第一个快照读创建Read View，之后的快照读获取的都是同一个Read View**

### RR 级别下能否防止幻读

**严谨的说，RR 级别下只能防止部分幻读**

首先，幻读通常指的是在同一个事务中，第二次查询发现了新增加的行，而第一次查询并没有返回这些新增加的行。

通过前面的例子，我们也看到了，在 RR 隔离级别下，由于一致性视图的存在，如果其他事务插入了新的行，在同一个事务中进行多次查询，这些新增的行将会被包含在事务的一致性视图中，确实可以避免部分幻读场景。

> 这里注意一下：MVCC解决的只是 RR 级别下快照读的幻读问题，而当前读的幻读问题则是通过临键锁来解决的。也就是说 RR 级别下是通过 MVCC+临键锁 来解决大部分幻读问题的。

为什么说是部分解决？看下面这个例子：

|     | 事务A                                        | 事务B                           |
| --- | ------------------------------------------ | ----------------------------- |
| T1  | begin                                      |                               |
| T2  |                                            | begin                         |
| T3  |                                            | select * from user            |
| T4  | insert into user(id, name) values(2, "小张') |                               |
| T5  |                                            | select * from user for update |
| T6  | commit                                     |                               |
| T7  |                                            | commit                        |

假设数据初始状态如下：

![](https://developer.qcloudimg.com/http-save/yehe-3763514/ac89a07ad791a01d3865d790f72029ae.png)

T3时刻看到的数据只有一条 `name = "小明"`，而T5时刻，由于 select * from user for update 使用的是当前读，读取的是最新的数据版本，T5时刻查询出来的数据是两条，name 分别为 "小明" 和 "小张"。

理解了上面的例子之后，再看下面这个例子：

|     | 事务A                                        | 事务B                                  |
| --- | ------------------------------------------ | ------------------------------------ |
| T1  | begin                                      |                                      |
| T2  |                                            | begin                                |
| T3  |                                            | select * from user                   |
| T4  | insert into user(id, name) values(2, "小张') |                                      |
| T5  |                                            | update user set name="小陈" where id=2 |
| T6  |                                            | select * from user                   |
| T7  | commit                                     |                                      |
| T8  |                                            | commit                               |

UPDATE 语句也是当前读，也会发生幻读问题，最终看到的数据是name 分别为 "小明" 和 "小陈"。

这里发生幻读的原因，和上面的例子是一样的，本质都是在一个事务中，即使用了快照读又使用了当前读，RR 级别下无法预防此种情况，所以说 RR 级别下无法完全解决幻读问题。

# Java 垃圾收集器

### **一、摘要**

在之前的文章中，我们介绍了对象的创建过程，以及运行期的相关优化手段。本文主要介绍对象回收的判定方式以及垃圾对象的回收算法等相关知识。

下面我们一起来了解一下。

### **二、对象回收判定方式**

当一个对象被创建时，虚拟机会优先分配到堆空间中，当对象不再被使用了，虚拟机会对其进行回收处理，以便释放内存空间，这个过程也被称为垃圾对象回收。

那么如何找到对象是否可以进行回收呢？一般有两种方式。

* 引用计数法
* 可达性分析法

下面我们一起来了解下相关知识。

##### **2.1、引用计数法**

这个方法的实现思路是：在对象中维护一个引用计数器，每当一个地方引用这个对象时，计数器值+1；当引用失效时，计数器值-1。当对象的计数器值为 0，表示这个对象不再被使用了，可以被回收。

这种方法使用场景很多，但很少有垃圾收集器会使用这种方式。

原因在于：这种方式存在一个致命的缺陷，比如堆中的两个对象相互引用，此时他们的计数器值是 1，但这两个对象并没有被外部使用，因此不会被回收，容易造成内存泄露。

##### **2.2、可达性分析法**

这个方法的实现思路是：从“GC Roots”（这个 GC Roots 可以是栈中的引用变量，也可以是方法区的引用变量或常量）开始扫描堆中的对象，沿着 GC Roots 一路扫描，被扫描的所有对象全部标记为存活对象；扫描完成之后，没有被标记的视为垃圾对象，可以被回收。

比如对象 A 被线程占中的变量 a 引用着，对象 A 中引用着对象 B，对象 B 又引用着 C 等，沿着 a 开始扫描，会扫描到对象 A，B，C 等，并把它们标记为存活对象。全部扫描完成之后，当一个对象到 GC Roots 没有任何引用链时，表示此对象是不可用的，等待被 GC 回收。

![](https://developer.qcloudimg.com/http-save/yehe-2156029/d46455e7b1b2128c2ed78ef6dfb4e7bd.jpg)

在 JVM 中，可以作为 GC Roots 的对象包括：

* 虚拟机栈中引用的对象
* 方法区中静态属性引用的对象
* 方法区中常量引用的对象
* 本地方法栈中 JNI（即 Native 方法）引用的对象

### **三、垃圾回收算法**

当一个对象被判定为垃圾对象之后，剩下的工作就是如何进行回收了。

下面我们一起来看看常见的几种垃圾回收算法的思想。

##### **3.1、标记-清除算法**

标记-清除算法如同它的名字一样，分为“标记”和“清除”两个阶段，也是最基础的算法。

首先标记出所有需要回收的对象，标记完成后统一回收所有被标记的对象。之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其缺点进行改进而得到的。

这个算法也有很多的不足，主要体现在效率和空间。

* 从效率的角度讲，标记和清除两个过程的效率都不高；
* 从空间的角度讲，标记清除后会产生大量不连续的内存碎片，空间碎片太多可能会导致后面的程序运行过程中分配较大对象时，无法找到足够的连续内存而不得不提前触发一次垃圾收集动作

标记-清除算法执行过程，可以用如下图来概括：

![](https://developer.qcloudimg.com/http-save/yehe-2156029/b67df670af9db54568ff91cf49ed23f1.png)

##### **3.2、复制算法**

复制算法是为了解决效率问题而出现的，它将可用的内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。

这样每次只需要对整个半区进行内存回收，内存分配时也不需要考虑内存碎片等复杂情况，只需要移动指针，按照顺序分配即可。

这个算法也有缺点，操作的时候内存会缩小为了原来的一半，代价很高；其次，持续复制长生存期的对象会导致回收效果不佳，效率较低。

一般的商用虚拟机会采用这种算法来回收**新生代（也称为年轻代）的对象**，不过研究表明`1:1`的比例不是很科学，因此新生代的内存空间被细划分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor；每次回收时，将 Eden 和 Survivor 空间中还存活的对象一次性复制到另外一块 Survivor 空间上，最后清理掉之前的 Eden 和 Survivor 空间。

HotSpot 虚拟机默认 Eden 和 Survivor 区的比例是`8 : 1 : 1`，期望每次回收后只有不到 10% 的对象存活，如果出现 Survivor 空间不够用时，需要依赖老年代进行分配担保。

复制算法执行过程，可以用如下图来概括：

![](https://developer.qcloudimg.com/http-save/yehe-2156029/caf28aac3ade28de140f44380c5754ff.png)

##### **3.3、标记-压缩算法**

在上面我们提到了复制算法的优点和缺点，针对对象存活率较高的场景，进行大量的复制操作时，效率很低下。如果不想浪费 50% 的空间，当对象 100% 存活时，那么需要有额外的空间进行分配担保。

在 HotSpot 虚拟机中，堆空间划分成两个不同的区域：**新生代**和**老年代**，目的是为了更有效率的回收对象。新生代的对象存活率低，会优先被回收，如果多次执行依然没有被回收，就会转移到老年代。老年代都是不易被回收的对象，对象存活率高，因此一般不能直接选用复制算法。

根据老年代的特点，有人提出了另外一种**标记-整理算法**，也称为**标记-压缩算法**，过程与**标记-清除算法**一样，不过不是直接对可回收对象进行清理，而是让所有存活对象都向一端移动，然后直接清理掉边界外的内存。

标记-整理算法执行过程，可以用如下图来概括：

![](https://developer.qcloudimg.com/http-save/yehe-2156029/57d128310f7de268c28add8137174840.png)

##### **3.4、分代收集算法**

分代收集算法，可以看成以上内容的延伸。它的实现思路是根据对象的生命周期的不同，将内存划分为几块，比如把堆空间划分为**新生代**和**老年代**，然后根据各块的特点采用最适当的收集算法。

在新生代中，存在大批对象死去、少量对象存活的特点，会采用**“复制算法”**，只需要付出少量存活对象的复制成本就可以完成垃圾对象收集，效率高；在老年代中，存在对象存活率高、没有额外空间对它进行分配担保的特点，会采用**“标记-清理”**或者**“标记-整理”**算法来进行回收。

可以用如下图来概括堆内存的空间布局：

![](https://developer.qcloudimg.com/http-save/yehe-2156029/c02d5d130616bddbfd9f6395996dad04.jpg)

### **四、垃圾收集器**

如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。

不同的虚拟机所提供的垃圾收集器可能会有很大差异，以 HotSpot 虚拟机为例，所包含的垃圾收集器可以用如下图来概括。

![](https://developer.qcloudimg.com/http-save/yehe-2156029/1baf3f56145ce1e257a14b0d254c6c79.png)

上图中的连线表示，不同分代的收集器可以搭配使用。

* 新生代收集器：Serial、ParNew、Parallel Scavenge
* 老年代收集器：Serial Old、CMS、Parallel Old
* 通用收集器： G1

在虚拟机中，没有所谓的万能收集器，只有根据具体的业务场景，选择最合适的收集器。这也是为什么 HotSpot 实现了这么多收集器的原因。

下面我们一起来看看相关的具体实现。

##### **4.1、Serial 和 Serial Old收集器**

Serial 系列的垃圾收集器是 JVM 的第一款收集器，它的设计思路很简单，在新生代，**使用单线程采用复制算法**进行收集对象；在老年代，**使用单线程采用标记整理算法**进行收集对象；垃圾收集的过程中会暂停用户线程，直到垃圾收集完毕。

因为当时的硬件环境配置都不高，内存都是几十兆，CPU 也都是单核的，不像现在这样处处都是高并发的应用场景。限于当时的硬件资源和应用场景，这个收集器优势很突出，简单高效、消耗资源也很少。

唯一的不足在于，在用户不可见的情况下要把用户正常工作的线程全部停掉，这对很多应用比较难以接受。不过实际上到目前为止，Serial 收集器依然是虚拟机在 Client 模式下运行的默认新生代收集器，因为它简单而高效。客户端应用模型下，分配给虚拟机管理的内存一般来说不会很大，收集几十兆甚至一两百兆的新生代对象，停顿时间平均在几十毫秒，只要不是频繁收集，完全可以接受。

整个流程，可以用如下图来概括。

![](https://developer.qcloudimg.com/http-save/yehe-2156029/9455e7b8311e647f362f263f550b301f.png)

总结下来，收集器特点如下：

* 收集区域： Serial（新生代），Serial Old（老年代）
* 收集算法： Serial（复制算法），Serial Old（标记整理算法）
* 收集方式：单线程
* 优势：简单高效，内存资源占用少，单核 CPU 环境最佳选项
* 劣势：整个搜集过程需要停顿用户线程，多核 CPU、大内存的环境，资源优势无法发挥起来

##### **4.2、ParNew收集器**

ParNew 收集器，可以看成是 Serial 收集器的多线程版本。除了使用多线程进行垃圾收集外，其余行为和 Serial 收集器完全一样，包括使用的也是复制算法，垃圾收集时暂停用户线程。在多核 CPU 资源环境下，可以显著提升整个垃圾收集的性能，也是虚拟机在 Server 模式下运行的首选新生代收集器。

能让 ParNew 出名的一个核心因素是，它是除了 Serial 收集器外，目前唯一一个能与 CMS 收集器配合一起使用的新生代收集器，因为 CMS 优秀所以 ParNew 也出名了，有点类似碰上了大款的感觉，其中 CMS 收集器是一款几乎可以认为有划时代意义的垃圾收集器，下文我们再讲。

其次，ParNew 收集器在单个 CPU 的环境中绝对不会有比 Serial 收集器更好的效果，甚至由于线程交互的开销，该收集器在两个 CPU 的环境中都不能百分之百保证可以超越 Serial 收集器。当然，随着可用 CPU 数量的增加，它对于垃圾收集的效率提升还是很有帮助的。

整个流程，可以用如下图来概括。

![](https://developer.qcloudimg.com/http-save/yehe-2156029/71a46f652784408e4a63656facaca419.png)

总结下来，收集器特点如下：

* 收集区域：新生代
* 收集算法：复制算法
* 收集方式：多线程
* 优势：多线程收集，多核 CPU 环境下效率要比 serial 高，新生代中，除了 Serial 收集器外目前唯一一个能与 CMS 配合的收集器
* 劣势：整个搜集过程需要停顿用户线程

##### **4.3、Parallel Scavenge 和 Parallel Old收集器**

Parallel Scavenge 和 ParNew 收集器很类似，也是一款使用多线程采用复制算法的新生代收集器；Parallel Old 收集器是一款使用多线程采用标记整理算法的老年代收集器；垃圾收集过程中也会暂停用户线程，直到整个垃圾收集过程结束。

不同的是，Parallel 收集器更关注系统的吞吐量，也被称为“吞吐量优先收集器”。

所谓吞吐量的意思就是 CPU 用于运行用户代码时间与 CPU 总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），比如虚拟机总运行 100 分钟，垃圾收集 1 分钟，那吞吐量就是 99%。高吞吐量可以高效率的利用 CPU 资源，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。

自适应调节策略也是 Parallel Scavenge 与 ParNew 的一个重要区别，用户可以通过参数来打开自适应调节策略，比如`-XX:+UseAdaptiveSizePolicy`参数，打开之后就不需要手动指定新生代大小、Eden 区和 Survivor 参数等细节参数了，虚拟机会根据当前系统的运行情况收集[性能监控](https://cloud.tencent.com/product/apm?from_column=20065&from=20065)信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量。如果对于垃圾收集器运作原理不太了解，优化比较困难的情况下，使用 Parallel 收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机去完成也是一个不错的选择。

另外，Parallel 收集器是虚拟机在 Server 模式下运行的默认垃圾收集器。

整个执行流程，跟 ParNew 收集器类似。

总结下来，收集器特点如下：

* 收集区域：Parallel Scavenge（新生代），Parallel Old（老年代）
* 收集算法：Parallel Scavenge（复制算法），Parallel Old（标记整理算法）
* 收集方式：多线程
* 优势：多线程收集，多核 CPU 环境下效率要比 serial 高
* 劣势：整个搜集过程需要停顿用户线程

##### **4.4、CMS收集器**

CMS 收集器是**一种以获取最短回收停顿时间为目标的老年代收集器**。

与前面几个收集器不同，它采用了一种全新的策略可以在垃圾回收过程中的某些阶段用户线程和垃圾回收线程一起工作，从而避免了因为长时间的垃圾回收而使用户线程一直处于等待之中。

目前很大一部分 Java 应用集中在互联网站或者 B/S 系统的服务端上，这类应用尤其注重服务的响应速度，希望系统停顿时间最短，比如在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过多少毫秒，以期给用户带来较好的体验，其中 CMS 收集器就非常符合这类应用的需求。

CMS 的英文全程是：Concurrent Mark-Sweep Collector，从名字上就能看出 CMS 收集器是基于“**标记-清除**”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为如下 4 个步骤：

* 初始标记
* 并发标记
* 重新标记
* 并发清除

CMS 会根据每个阶段不同的特性来决定是否停顿用户线程。整个流程，可以用如下图来概括。（图片来自于勤劳的小手 - 垃圾收集器文章）

![](https://developer.qcloudimg.com/http-save/yehe-2156029/0786fd5fd0f7df9d980f6fe7b1302200.jpg)

###### **4.4.1、阶段一：初始标记**

初始标记阶段的工作主要是标记一下 GC Roots 能直接关联到的对象，这个过程会短暂的停顿用户线程，因为并不会对整个 GC Roots 的引用进行遍历，因此速度很快。

###### **4.4.2、阶段二：并发标记**

并发标记阶段的工作主要是把阶段一标记好的 GC Roots 对象进行深度的遍历，找到所有与 GC Roots 关联的对象并进行标记，这个过程会采用多线程的方式进行遍历标记，因为非常耗时，CMS 考虑到为了尽量不停顿用户线程，因此这个阶段不会暂停用户线程，也就是说，此时 JVM 会分配一些资源给用户线程执行任务，通过这样的方式减少用户线程的停顿时间。

###### **4.4.3、阶段三：重新标记**

重新标记阶段的工作主要是修补阶段二用户线程运行期间产生新的垃圾对象，进行重新标记，同样也是采用多线程方式进行，此阶段数量不会很多，会短暂的停顿用户线程，速度也很快。

###### **4.4.4、阶段四：并发清除**

并发清除阶段的工作主要是对那些被标记为可回收的对象进行清理，在一般情况下，并发清除阶段是使用的是“**标记-清除**”算法，因为这个过程不会牵扯到对象的地址变更，所以 CMS 在并发清除阶段是不需要停止用户线程的，对象回收效率非常高。

与此同时，正因为并发清除阶段用户线程也可以同时运行，所以在用户线程运行的过程中自然也会产生新的垃圾对象，这也就是导致 CMS 收集器会产生“**浮动垃圾**”的原因，此时也会产生很多的**空间碎片**，当空间碎片到达了一定程度时，此时 CMS 就会使用“**标记-整理**”算法来解决空间碎片的问题。

在上文的垃圾回收算法中我们有说到，“**标记-整理**”算法会将对象的位置进行挪动并更新对象的引用的指向地址，在这个过程中，如果用户线程同时运行的话会产生并发问题，因此当 CMS 进行碎片整理的时候必须得停止用户线程。所以，在某些情况下，并发清除阶段 CMS 也会停顿用户线程。

CMS 收集器作为一个全新思路的垃圾收集器，虽然很优秀，但一直没有被 Hospot 虚拟机纳入为默认的垃圾收集器。时至今日，JDK1.8 使用的默认收集器都还是 Parallel scavenge 和 Parallel old 收集器，主要原因在于 CMS 存在一些比较头疼的问题，比如浮动垃圾、空间碎片整理时会造成系统卡顿、在并发清除阶段可能会出现系统长时间的假死。

###### **4.4.5、小结**

总结下来，收集器特点如下：

* 收集区域：老年代
* 收集算法：标记清除算法 \+ 标记整理算法
* 收集方式：多线程
* 优势：多线程收集过程中可以做到不停止用户线程，以获取最短回收停顿时间
* 劣势：会产生浮动垃圾、空间碎片整理时会造成系统卡顿、并发清除阶段可能会出现系统假死等问题

##### **4.5、G1收集器**

G1（Garbage-First）收集器是当今收集器技术发展的最前沿成果之一，从 JDK 7 Update 4 后开始进入商用。

在 G1 收集器出现之前，不管是 Serial 系列，Parallel 系列，还是 CMS 收集器，它们都是基于把内存进行物理分区的形式将 JVM 内存分成新生代、老年代、永久代或 MetaSpace，这种分区模式下进行垃圾收集时必须对某个区域进行整体性的收集，比如整个新生代、整个老年代收集或者整个堆，当内存空间不大的时候，比如几个 G，通过参数优化能取得不错的收集性能。但是，随着硬件资源的发展，JVM 可用内存从几十 G 到几百 G 甚至上 T 时，这种采用传统模式下的物理分区进行收集时，每次扫描内存的区域自然就变大了，进行垃圾清理的时间自然就变得更长了，此时传统的收集器即时再怎么优化，也难以取得令人满意的收集效果，因此需要一款全新的垃圾收集器。

G1 收集器就是在这样的环境下诞生的，它摒弃了原来的物理分区，把整个 Java 堆分成若干个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离，它们都是一部分 Region 的集合。从结构上看，G1 收集器不要求整个新生代或者老年代都是连续的，也不再坚持固定大小和固定数量，它会跟踪各个 Region 里面的垃圾堆积的价值大小，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。这种通过 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限的时间内可以获取尽可能高的收集效率。

G1 收集器内存划分，可以用如下图来概括。（图片来自于勤劳的小手 - 垃圾收集器文章）

![](https://developer.qcloudimg.com/http-save/yehe-2156029/4fc1c8480338576b6f85d9979c0b3669.jpg)

在 G1 收集器里面维护了一个 Collect Set 集合，这个集合里面记录了待回收的 Region 区域信息，同时也包括了每个 Region 区域可回收的大小空间。通过 Collect Set 里面的信息，G1 在进行垃圾收集时，可以根据用户设定的可接受停顿时间来进行分析，在设定的时间范围内优先收集垃圾最多的 Region 区域，以实现高吞吐、低停顿的收集效果。

在工作流程上，G1 收集器也吸收了 CMS 很多优秀的收集思路，整个垃圾收集过程，可以分为如下 4 个步骤：

* 初始标记
* 并发标记
* 重新标记
* 筛选回收

G1 收集器的垃圾回收流程和 CMS 逻辑大致相同，主要的区别在最后一个阶段，G1 不会直接进行清除，而是会根据设置的停顿时间进行智能的筛选和局部的回收，采用“**标记复制**”算法来实现。

整个流程，可以用如下图来概括。

![](https://developer.qcloudimg.com/http-save/yehe-2156029/64ede9eb0a89a5e15eab63f637da7944.jpg)

###### **4.5.1、阶段一：初始标记**

此阶段的工作内容与上文介绍的 CMS 收集器一样，会先把所有 GC Roots 直接引用的对象进行标记，同时会短暂的停止用户线程，因为不会对整个 GC Roots 的引用进行遍历，因此速度比较快。

###### **4.5.2、阶段二：并发标记**

此阶段的工作内容与上文介绍的 CMS 收集器也一样，找到所有与 GC Roots 关联的对象并进行深度遍历标记，会采用多线程的方式进行遍历标记，因为比较耗时，为了尽量不停顿用户线程，这个阶段 GC 线程会和用户线程同时运行，通过这样的方式减少用户线程的停顿时间。

###### **4.5.3、阶段三：重新标记**

此阶段的工作内容与上文介绍的 CMS 收集器也是一样，针对阶段二用户线程运行的过程中产生新的垃圾，采用多线程方式进行重新标记，为了避免这个过程再次产生新的垃圾对象，会短暂的停止用户线程，因为数量不会很多，因此速度比较快。

###### **4.5.4、阶段四：筛选回收**

筛选回收阶段的工作主要是把存活的对象复制到 Region 空闲区域，同时会根据 Collect Set 记录的可回收 Region 信息进行筛选，计算 Region 回收成本，接着根据用户设定的停顿时间值制定回收计划，最后根据回收计划筛选合适的 Region 区域进行垃圾回收。

从局部来看，G1 使用的是复制算法，将存活对象从一个 Region 区域复制到另一个 Region 空闲区域；但从整个堆来看，G1 使用的逻辑又相当于标记整理算法，每次垃圾收集时会把存活的对象整理到对应可用的 Region 区域，再把原来的 Region 区域标记为可回收区域并记录到 Collect Set 中，因此 G1 的每一次回收都可以看作是一次标记整理过程，两者都不会产生空间碎片问题。

###### **4.5.5、小结**

总结下来，收集器特点如下：

* 收集区域：整个堆内存
* 收集算法：复制算法
* 收集方式：多线程
* 优势：停顿时间可控，吞吐量高，不会产生空间碎片，不需要额外的收集器搭配
* 劣势：目前而言，相较于 CMS，G1 还不具备全方位、压倒性优势，G1 在收集过程中内存占用和执行负载都偏高；其次，在小内存应用上 CMS 的表现大概率会优于 G1，而 G1 在大内存应用上会比较有优势，6G 以上的内存可以考虑使用 G1 收集器

##### **4.6、常用的收集器组合**

最后我们对以上介绍的垃圾收集器进行一次汇总，同时介绍一下[服务器](https://cloud.tencent.com/product/cvm?from_column=20065&from=20065)端常用的组合模式，内容如下。

| 服务器组合 | 新生代收集器            | 老年代收集器           | 备注                                                                                                                                                                             |
| ----- | ----------------- | ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| 组合一   | Serial            | Serial Old       | Serial 是一个使用单线程采用复制算法的新生代收集器；Serial Old 是一个使用单线程采用标记整理算法的老年代收集器，GC 时会暂停所有应用线程，可以使用-XX:+UseSerialGC选项来开启                                                                        |
| 组合二   | ParNew            | Serial Old       | ParNew 是一个使用多线程采用复制算法的新生代收集器，GC 时会暂停所有应用线程，可以使用-XX:+UseParNewGC选项来开启                                                                                                           |
| 组合三   | Parallel Scavenge | Serial Old       | Parallel Scavenge 是一个使用多线程采用复制算法的新生代收集器，GC 时会暂停所有应用线程，可以使用-XX:+UseParallelGC选项来开启；需要注意的是，在jdk1.7及之前的版本中，这个参数默认采用 Serial Old 作为老年代收集器；在jdk1.8及之后的版本中，默认采用 Parallel Old 作为老年代收集器 |
| 组合四   | Parallel Scavenge | Parallel Old     | Parallel Old是 Serial Old 的多线程版收集器，可以使用-XX:+UseParallelOldGC选项来开启                                                                                                               |
| 组合五   | Serial            | CMS + Serial Old | CMS 是一个使用多线程采用标记清楚算法的老年代收集器，可以实现 GC 线程和用户线程并发工作，不需要暂停所有用户线程；另外，可以将 Serial Old 收集器作为备选，当 CMS 进行 GC 失败时，会自动使用 Serial Old 进行 GC；可以使用-XX:+UseConcMarkSweepGC选项来开启                  |
| 组合六   | ParNew            | CMS + Serial Old | ParNew 是除了 Serial 以外，唯一一个能搭配 CMS 的新生代收集器；可以使用-XX:+UseConcMarkSweepGC开启，默认使用 ParNew 作为新生代收集器，也可以通过-XX:+UseParNewGC强制指定 ParNew                                                   |
| 组合七   | G1                | G1               | G1 是一个新一代的垃圾收集器，摒弃了原来的物理分区，把整个 Java 堆分成若干个大小相等的独立区域（Region），针对局部区域使用多线程采用复制算法进行筛选回收，可以使用-XX:+UseG1GC选项来开启                                                                      |

### **五、方法区回收**

以上介绍的都是对象的回收过程，在之前的 JVM 内存结构的文章中我们介绍到，Java 应用程序运行时，除了堆空间会存在垃圾数据以外，方法区同样也存在。

虽然虚拟机规范中没有明确要求方法区一定要实现垃圾回收，主要原因在于这个区域的垃圾回收效率非常低，但是 HotSpot 虚拟机对方法区也会进行回收的，主要回收的是**废弃常量**和**无用的类**两部分。

如何判断一个常量是否为“废弃常量”呢？其实很简单，只要当前系统中没有任何一处引用该常量，就会被判定为废弃常量。

如何判断一个类是否为“无用的类”呢？条件非常苛刻，需要同时满足以下三点。

* 1.该类所有实例都已经被回收，也就是说 Java 堆中不存在该类的任何实例
* 2.该类对应的`java.lang.Class`对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法
* 3.加载该类的 ClassLoader 已经被回收，也就是说这个类的类加载器被卸载回收了

满足以上三个条件则表示这个类再也无用了，HotSpot 虚拟机会对此类进行回收。例如在大量使用反射、动态代理、CGLib 等 ByteCode 框架，并自定义 ClassLoader 创建的类，为了保证方法区不会溢出，虚拟机会在适当的情况下对无用的类进行回收。

在 JDK1.7 及以前的版本中，用永久代来作为方法区的实现，当永久代的空间不足时会触发 Full GC。

在 JDK1.8 及之后的版本中，用元空间来作为方法区的实现，元空间的内存空间默认使用的是操作系统的内存空间，它的垃圾回收不再由 Java 来控制，元空间的内存管理由元空间虚拟机来完成。

# OOM是如何产生的

## 一、什么是OOM

OOM 是 Out Of Memory 的缩写，意思是内存耗尽。在计算机领域中，当系统的内存资源不足以满足程序或进程的需求时，就会发生OOM错误，导致程序崩溃或系统变得不稳定。这通常发生在运行大型程序或者同时运行多个程序时，特别是对于内存资源要求较大的应用程序或者服务来说。OOM问题可能需要通过优化程序代码、增加内存容量或者调整系统参数来解决。

Java中的OOM是java.lang.OutOfMemoryError的子类，常见的有：

- Java heap space：堆空间不足

- GC Overhead limit exceeded：GC效率低下

- PermGen space/Metaspace：方法区溢出

- Unable to create new native thread：线程创建失败

- Requested array size exceeds VM limit：数组过大

- Direct buffer memory：直接内存溢出

- Code cache：代码缓存区满

- Kill process or sacrifice child：Linux系统级限制

## 二、堆内存溢出（Heap OOM）

堆内存溢出（Heap OOM）指的是在Java虚拟机中，堆内存资源不足以满足程序的需求，导致发生OutOfMemoryError的错误。堆内存是Java虚拟机运行时的一块内存区域，用于存储对象实例和数组等动态分配的内存。

当程序中创建的对象或者数组数量过多，或者单个对象/数组占用的内存过大，超过了堆内存的限制，就会导致堆内存溢出。这通常发生在以下情况：

1. 程序中创建了大量的对象，但没有及时释放，导致堆内存被占满。

2. 程序中创建了过大的数组，占用了大量的堆内存空间。

3. 内存泄漏：程序中存在对象引用无法被及时释放的情况，导致堆内存不断增加，最终耗尽堆内存资源。

解决堆内存溢出的方法包括：

1. 增加堆内存的大小，通过调整JVM参数（如-Xmx和-Xms）来增加堆内存的限制。

2. 优化程序代码，及时释放不再使用的对象或者数组，避免内存占用过大。

3. 定位和修复内存泄漏问题，确保对象引用能够被正确释放。

4. 使用内存分析工具，如MAT（Memory Analyzer Tool），帮助分析内存使用情况，找出潜在的内存泄漏问题。

## 三、方法区内存溢出（Metaspace OOM）

方法区（Method Area）是Java虚拟机中的一块内存区域，用于存储类的结构信息、常量、静态变量等数据。在Java 8及之前的版本，方法区是位于堆内存中的一部分。而从Java 8开始，方法区被替换为元空间（Metaspace），并且不再位于堆内存中。

方法区内存溢出（Metaspace OOM）指的是元空间（Metaspace）资源不足以满足Java虚拟机加载类、存储常量池、静态变量等信息的需求，导致发生OutOfMemoryError的错误。在发生Metaspace OOM时，通常会抛出"Metaspace"或"PermGen space"相关的错误。

Metaspace OOM的原因主要包括以下几个方面：

1. 类过多或过大：当Java虚拟机加载的类太多或者单个类的大小过大时，会耗尽Metaspace的内存资源。

2. 字符串常量池：字符串常量池也存储在方法区（或元空间）中，如果程序中使用大量的字符串，尤其是动态生成的字符串，会导致Metaspace的内存占用增加。

3. 动态代理：动态代理在运行时生成代理类，如果代理类过多，会导致Metaspace的内存资源紧张。

解决Metaspace OOM的方法主要包括：

1. 增加Metaspace的大小：通过调整JVM参数（如-XX:MetaspaceSize和-XX:MaxMetaspaceSize）来增加Metaspace的限制。

2. 优化类加载和卸载：避免过多的动态生成类，合理管理类的加载和卸载。

3. 优化字符串的使用：避免大量动态生成的字符串，尽量复用字符串对象。

4. 使用工具分析：使用工具如VisualVM、jmap、jstat等进行内存分析，定位Metaspace OOM的原因，并进行相应的优化。

Metaspace相对于传统的方法区，不再有固定的大小限制，可以动态地调整大小，但是仍然需要合理配置和管理，以避免Metaspace OOM的发生。

## 四、栈内存溢出（Stack OOM）

栈内存溢出（Stack OOM）指的是在程序执行时,栈空间不足以支持递归调用或者方法调用链过长,导致发生StackOverflowError的错误。栈内存是用来存储方法的执行环境和局部变量的内存区域。每当一个方法被调用时,Java虚拟机会为该方法创建一个栈帧,用于存储方法的参数、局部变量和方法返回值等信息。当方法调用结束时,对应的栈帧会被销毁。当程序中的方法调用过多或者递归调用没有终止条件时,栈空间会不断分配新的栈帧,导致栈内存不断增长,最终耗尽栈内存资源,触发栈内存溢出。

解决栈内存溢出的方法主要包括：

1. 优化递归算法：确保递归调用有合理的终止条件,避免无限递归导致栈内存溢出。

2. 增加栈内存大小：通过调整JVM参数（如-Xss）来增加栈内存的限制。增加栈内存的同时也要注意不要过度增加,以免占用过多的系统资源。

3. 优化方法调用链：减少不必要的方法调用,避免过长的方法调用链。

4. 使用迭代代替递归：对于递归调用较深的情况,可以尝试使用迭代的方式来替代递归,减少栈内存的消耗。

栈内存的大小是有限制的,在递归调用较深或者方法调用链较长的情况下,容易触发栈内存溢出。因此,在设计程序时应注意合理管理方法的调用和递归的使用,以避免栈内存溢出的问题。

Java中的OutOfMemoryError（[OOM](https://so.csdn.net/so/search?q=OOM&spm=1001.2101.3001.7020 "OOM")）是当JVM内存不足时抛出的错误。本文将全面剖析JVM中产生OOM的各种情况，包括堆[内存溢出](https://so.csdn.net/so/search?q=%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA&spm=1001.2101.3001.7020)、方法区溢出、栈溢出等，并提供详细的诊断方法和解决方案。

二、堆内存溢出（Java heap space）
------------------------

2.1 产生原因

当对象需要分配到堆内存时，如果堆内存不足且无法通过GC回收足够空间时抛出。

// 典型示例

    public class HeapOOM {    public static void main(String[] args) {        List<Object> list = new ArrayList<>();        while(true) {            list.add(new byte[1024*1024]); // 每次分配1MB        }    }}

2.2 错误信息

    java.lang.OutOfMemoryError: Java heap space

2.3 解决方案

调整堆大小：

    -Xms256m -Xmx1024m  # 初始堆256MB，最大堆1GB

内存分析：

使用jmap获取堆转储：

    jmap -dump:format=b,file=heap.hprof <pid>

使用MAT/Eclipse Memory Analyzer分析

代码优化：

避免内存泄漏（如静态集合、未关闭资源）  
使用对象池重用对象

三、GC开销超限（GC Overhead limit exceeded）
---------------------------------------

3.1 产生原因

当JVM花费超过98%的时间进行GC，但只恢复了不到2%的堆空间时抛出。

// 典型场景：创建大量生命周期短的对象

    public class GCOverheadOOM {    public static void main(String[] args) {        Map<Key, String> map = new HashMap<>();        while(true) {            for(int i=0; i<10000; i++) {                map.put(new Key(i), "Value"+i);            }            map.clear(); // 不完全清除        }    }} 

3.2 错误信息

    java.lang.OutOfMemoryError: GC Overhead limit exceeded

3.3 解决方案

1. ##### 增加堆大小：
   
       ​-Xmx2g -XX:+UseG1GC ​

2. ##### 优化GC策略：
* 对于大量短生命周期对象，使用G1或ZGC
* 调整新生代大小：
* -XX:NewRatio=2  # 新生代占堆的1/3
1. ##### 代码改进：
* 减少临时对象创建
* 使用更高效的数据结构

四、方法区溢出（Metaspace/PermGen）
--------------------------

4.1 产生原因

JDK8前称为PermGen space，JDK8+称为Metaspace，存储类元数据信息。

    // 通过动态生成类填满方法区public class MetaspaceOOM {    static class OOMObject {}        public static void main(String[] args) {        while(true) {            Enhancer enhancer = new Enhancer();            enhancer.setSuperclass(OOMObject.class);            enhancer.setUseCache(false);            enhancer.setCallback((MethodInterceptor) (o, method, objects, methodProxy) ->                 methodProxy.invokeSuper(o, objects));            enhancer.create(); // 动态创建类        }    }} 

4.2 错误信息  
 

    // JDK7及之前java.lang.OutOfMemoryError: PermGen space // JDK8+java.lang.OutOfMemoryError: Metaspace 

4.3 解决方案

调整Metaspace大小：

    -XX:MaxMetaspaceSize=256m

JDK8前调整PermGen：

    -XX:MaxPermSize=128m

减少动态类生成：

缓存动态代理类  
限制反射使用

五、线程栈溢出（Unable to create new native thread）
-------------------------------------------------------------------------------------------------------------------------------------

5.1 产生原因

当创建线程数量超过系统限制时发生。

    public class ThreadOOM {    public static void main(String[] args) {        while(true) {            new Thread(() -> {                try { Thread.sleep(100000); }                 catch(InterruptedException e) {}            }).start();        }    }}

5.2 错误信息

    java.lang.OutOfMemoryError: Unable to create new native thread

5.3 解决方案

减少线程数量：

使用线程池：

    ExecutorService pool = Executors.newFixedThreadPool(100);

调整系统限制：

    ulimit -u  # 查看最大线程数ulimit -u 2048  # 设置最大线程数

减少栈大小：

    -Xss256k  # 默认1MB，减少可创建更多线程

六、直接内存溢出（Direct buffer memory）
------------------------------------

6.1 产生原因

NIO使用的直接内存（堆外内存）不足时抛出。

    public class DirectMemoryOOM {    public static void main(String[] args) {        // 绕过DirectByteBuffer限制，直接分配内存        List<ByteBuffer> buffers = new ArrayList<>();        while(true) {            buffers.add(ByteBuffer.allocateDirect(1024*1024)); // 1MB        }    }}

6.2 错误信息

    java.lang.OutOfMemoryError: Direct buffer memory

6.3 解决方案

调整直接内存大小：

    -XX:MaxDirectMemorySize=256m

显式回收：

    ((DirectBuffer)buffer).cleaner().clean();

使用池化技术：

Netty的ByteBuf池

七、数组过大溢出（Requested array size exceeds VM limit）
--------------------------------------------------

7.1 产生原因

尝试分配超过JVM限制的数组。

    public class ArraySizeOOM {    public static void main(String[] args) {        int[] arr = new int[Integer.MAX_VALUE]; // 约2^31-1个元素    }} 

7.2 错误信息

    java.lang.OutOfMemoryError: Requested array size exceeds VM limit

7.3 解决方案  
减小数组大小：

分块处理大数据  
使用集合替代：

    List<Integer> list = new ArrayList<>();

调整数据结构：

使用数据库或文件存储

八、代码缓存溢出（Code cache）
-----------------------

8.1 产生原因

JIT编译的代码填满代码缓存区。

// 通常由大量方法被JIT编译导致

    public class CodeCacheOOM {    public static void main(String[] args) {        // 需要大量方法编译的代码    }}

8.2 错误信息

    java.lang.OutOfMemoryError: Code cache

8.3 解决方案  
增加代码缓存大小：

    -XX:ReservedCodeCacheSize=256m

减少编译阈值：

    -XX:CompileThreshold=10000

关闭分层编译：

    -XX:-TieredCompilation

九、系统级OOM（Kill process or sacrifice child）
-----------------------------------------------

9.1 产生原因  
Linux系统的OOM Killer终止进程。

    dmesg | grep -i kill

输出示例：

    Out of memory: Kill process 12345 (java) score 999 or sacrifice child

9.2 解决方案  
增加系统内存  
调整OOM Killer策略：

    echo -17 > /proc/[pid]/oom_adj

限制容器内存（Docker）：

    docker run -m 2g my-java-app

十、OOM诊断工具链
----------------

OOM诊断工具链

| 工具        | 用途      | 示例命令                                     |
| --------- | ------- | ---------------------------------------- |
| jstat     | 监控内存和GC | jstat -gcutil 1000                       |
| jmap      | 堆转储     | jmap -dump:live,format=b,file=heap.hprof |
| jvisualvm | 可视化分析   | 图形化界面                                    |
| MAT       | 内存分析    | 分析hprof文件                                |
| jcmd      | 多功能工具   | jcmd VM.native_memory                    |

## 十一、OOM预防最佳实践

代码层面：

避免内存泄漏（监听器、静态集合）  
及时关闭资源（数据库连接、文件流）  
使用WeakReference处理缓存  
JVM配置：

\# 基础配置示例

    -Xms1g -Xmx2g -XX:MaxMetaspaceSize=256m -XX:+UseG1GC -XX:MaxGCPauseMillis=200

监控预警：

JMX监控堆内存使用  
Prometheus + Grafana监控体系  
设置合理的GC日志监控：

    -Xlog:gc*:file=gc.log:time:filecount=5,filesize=10M

十二、总结
-----------

OOM类型与对应解决方案速查表：

| OOM类型                   | 相关内存区域  | 典型解决方案                     |
| ----------------------- | ------- | -------------------------- |
| Java heap space         | 堆       | 增大堆，修复内存泄漏                 |
| GC Overhead             | 堆       | 优化GC策略，减少对象创建              |
| Metaspace/PermGen       | 方法区     | 增大Metaspace，减少动态类生成        |
| Unable to create thread | 栈       | 减少线程数，调整-Xss               |
| Direct buffer           | 直接内存    | 增大MaxDirectMemorySize，显式回收 |
| Array size              | 堆       | 减小数组尺寸，分块处理                |
| Code cache              | JIT代码缓存 | 增大ReservedCodeCacheSize    |
| System OOM              | 系统内存    | 增加物理内存，调整OOM Killer        |

# 大QPS处理方案

为一栋楼的场景设计数据存储方案，要达到2000到7000的QPS（每秒查询量），这个目标在现代分布式存储系统中是完全可以实现的。下面我为你梳理一个从技术选型到架构设计的完整方案。

首先，一个清晰的表格可以帮你快速了解不同技术路线的核心选择：

| 技术路线            | 推荐产品/方案                                                                                                                                                                                                                                                            | 核心优势                                             | 适用场景/说明                                    |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------ | ------------------------------------------ |
| **云原生多模数据库**    | **阿里云 Lindorm**[](https://help.aliyun.com/zh/lindorm/use-cases/hightopo-use-case)                                                                                                                                                                                  | 超融合架构，一份数据支持多种查询；高吞吐写入；兼容多种生态（如HBase, OpenTSDB）。 | 楼宇内**多源异构数据**（如设备监控、日志、用户信息）的统一存储，简化架构。    |
| **分布式NoSQL数据库** | **京东云列式存储**[](https://developer.jdcloud.com/article/185)<br>**Aerospike**[](http://www.360doc.com/content/20/0525/11/21412_914411302.shtml)                                                                                                                        | 高性能随机读写；可轻松支持**千万级QPS**；高可扩展性。                   | 楼宇物联网设备产生的**海量时序数据**（如传感器读数）；需要高并发读写的业务数据。 |
| **高性能分布式存储**    | **华为 OceanStor Pacific**[](https://e.huawei.com/cn/documents/solutions/ict-service-provider/569ad5bd24b041209ea3a238b0ddd6a4)<br>**中兴 KS20000**[](https://www.zte.com.cn/china/product_index/cloud_core_network/cloud-infrastructure/tecs0/tecs-clovestorage.html) | 企业级高可靠性与高性能；支持块、文件、对象等多种协议；线性扩展。                 | 作为**私有化部署**的存储资源池，承载楼宇所有的结构化与非结构化数据。       |

### 💡 架构设计与优化建议

选择了技术方向后，合理的架构设计是达成目标的关键。以下是一些通用的核心优化思路，适用于多数方案：

- **数据分片与并行读写**：采用合适的分片策略（如结合哈希与范围划分），将数据分散到不同物理节点上[](https://www.ctyun.cn/developer/article/680317292572741)。这样读写请求可以并发处理，避免单点瓶颈，显著提升吞吐量。这在处理大规模数据时，效果尤为明显[](https://www.ctyun.cn/developer/article/680317292572741)。

- **智能缓存技术**：构建多级缓存体系（客户端、分布式、存储节点本地）来应对热点数据的高频访问[](https://www.ctyun.cn/developer/article/680317292572741)。通过改进的LRU等智能调度算法，可以动态调整缓存内容，这在热点数据访问场景下能显著降低读写延迟[](https://www.ctyun.cn/developer/article/680317292572741)。

- **存储介质的选择**：根据数据的热度采用**分层存储**架构[](https://www.ctyun.cn/developer/article/680317292572741)。将高频访问的热数据（如实时监控数据）放在**NVMe SSD**上以确保低延迟；将低频访问的冷数据（如历史日志）迁移至**SATA SSD**或**HDD**以节约成本[](https://help.aliyun.com/zh/tablestore/product-overview/estimate-resource-usage-and-select-storage-types)[](https://www.ctyun.cn/developer/article/680317292572741)。

- **精细化的数据库调优**：如果选用类似ClickHouse的分析型数据库，可以通过**调整索引粒度**等参数来优化点查询性能[](https://www.volcengine.com/docs/6464/1799867)。更精细的索引意味着查询时需要扫描的数据量更少，能有效提升查询速度[](https://www.volcengine.com/docs/6464/1799867)。

### 💎 方案选择与实施

综合来看，你的选择可以遵循以下路径：

1. **首选云服务**：如果业务部署在云端，优先考虑**阿里云Lindorm**[](https://help.aliyun.com/zh/lindorm/use-cases/hightopo-use-case)或**京东云列式存储**[](https://developer.jdcloud.com/article/185)这类托管服务。它们开箱即用，免运维，并能轻松应对你设定的QPS目标，尤其适合物联网和实时监控场景。

2. **考虑私有化部署**：如果数据需要留在本地机房，**华为OceanStor Pacific**[](https://e.huawei.com/cn/documents/solutions/ict-service-provider/569ad5bd24b041209ea3a238b0ddd6a4)或**中兴KS20000**[](https://www.zte.com.cn/china/product_index/cloud_core_network/cloud-infrastructure/tecs0/tecs-clovestorage.html)这类成熟的分布式存储产品是可靠选择，能提供企业级的高可靠和高性能。

3. **关注成本与特定场景**：对于追求极致性价比且业务以KV查询为主的场景，可以像“个推”一样，评估从Redis迁移到**Aerospike**[](http://www.360doc.com/content/20/0525/11/21412_914411302.shtml)的方案，它能用更少的资源支撑海量数据。

希望这份详细的方案能帮助你构建一个高性能、高可用的楼宇数据存储系统。如果你能分享更多关于数据类型（如时序数据、用户信息还是视频日志）和预算的信息，我可以为你提供更精准的建议。

# 在读数据状况的存储查询逻辑

好的，我理解您的问题是在楼宇数据存储系统中，需要处理一种特定的查询场景——**频繁地「读取数据的当前状态或状况」**，并希望设计一个高效的存储和查询逻辑。

这种「当前状态读取」通常是系统的**热点操作**，对低延迟和高并发要求很高。下面我将为您提供一个从数据模型到缓存策略的完整设计方案。

### 💡 核心设计思想：读写分离

核心思想是将**高频的写操作**与**高频的读操作**在物理和逻辑上分离开：

- **写路径**：负责接收和持久化数据更新。可以设计为顺序写入，追求高吞吐。

- **读路径**：负责以极低的延迟返回最新状态。可以设计为直接从内存或优化过的存储中获取。

整个数据流转与查询逻辑，可以清晰地体现在下图中：

---

### 方案一：KV分离 + 缓存（最常用且高效）

这种方法将「最新状态」单独存储，使其可以被快速定位和访问。

#### 1. 数据模型设计

- **「最新状态」记录区 (current_state_table)**
  
  - **Key**: `device_id` (设备唯一标识) 或 `sensor_id:latest`
  
  - **Value**: `{"temperature": 25.5, "humidity": 60, "power": "on", "last_updated": 1646123456789}`
  
  - **特点**: 每个设备或数据点只有一条记录，**Key-Value结构**，更新即覆盖。

- **「历史明细」存储区 (history_table)**
  
  - **Row Key**: `device_id_timestamp` (例如: `sensor_001_1646123456789`)
  
  - **Columns**: 各个数据字段。
  
  - **特点**: 每条更新都追加新记录，**时序结构**，用于历史查询和审计。

#### 2. 存储选型

- **「最新状态」存储**:
  
  - **Redis**: 纯内存操作，微秒级延迟。非常适合存储KV形式的最新状态。QPS可达数十万，远超你的要求。
  
  - **Aerospike**: 混合架构，性能接近Redis，但数据可持久化到SSD，成本更低，同样能轻松支撑千万级QPS。

- **「历史明细」存储**:
  
  - **Cassandra / ScyllaDB**: 高写入吞吐，适合存储海量时序数据。
  
  - **ClickHouse**: 若需频繁做历史数据分析，这是绝佳选择。
  
  - **时序数据库**: 如 InfluxDB、TDengine，为时序场景做了专门优化。

#### 3. 查询逻辑

- **查询当前状况**:
  
  - 应用直接根据 `device_id` 去 **Redis** 或 **Aerospike** 中 `GET` 对应的Key。
  
  - **延迟**: 亚毫秒到毫秒级。
  
  - **QPS**: 轻松突破2k-7k。

- **查询历史数据**:
  
  - 应用去 **Cassandra** 或 **ClickHouse** 中，根据 `device_id` 和时间范围进行查询。

#### 4. 数据同步逻辑

这是一个关键点，如何保证「最新状态」区的数据是最新的？

- **方式A: 双写 (不推荐)**： 应用同时写入「最新状态」区和「历史明细」区。问题在于存在数据不一致的风险。

- **方式B: 写时同步更新 (推荐)**:
  
  1. 应用首先将数据写入「历史明细」区（例如 Cassandra）。
  
  2. 写入成功后，**立即更新**「最新状态」区（例如 Redis）。
  
  3. 这种方式保证了状态和数据流水的一致性。虽然有一次额外写入，但写操作通常远低于读操作的QPS，所以对整体性能影响很小。

---

### 方案二：单数据库 + 物化视图（架构更简单）

如果希望架构更简单，减少组件依赖，可以依赖现代数据库自身的功能。

#### 1. 数据模型设计

- **仅有一张「全量数据」表 (raw_data_table)**
  
  - 包含所有原始更新记录。

#### 2. 实现方案

- **使用物化视图 (Materialized View)**:
  
  - 数据库（如 **ClickHouse**、**TiDB** 或 **ScyllaDB**）可以创建一个物化视图 `current_state_mv`。
  
  - 这个视图会自动地、近乎实时地从 `raw_data_table` 中计算每个 `device_id` 的**最新一条记录**。
  
  - 应用查询时，直接 `SELECT * FROM current_state_mv WHERE device_id = ?`，数据库内部已经将其优化为一次快速查询。

#### 3. 查询逻辑

- **查询当前状况**: 直接查询物化视图。

- **优势**: 架构简单，无需维护多个数据存储和同步逻辑。数据强一致。

- **注意**: 物化视图的刷新会有微小的延迟，并且会对源表的写入带来一些额外开销。需要测试其QPS是否能稳定达到你的要求。

---

### ⚙️ 实战优化技巧

无论选择哪种方案，以下技巧都能进一步提升性能：

1. **缓存预热与更新**:
   
   - **预热**: 系统启动时，从历史数据中加载所有设备的最后一次状态到Redis。
   
   - **更新**: 数据更新时，采用 **"先更新数据库，再删除缓存"** 的策略，下次读取时自动回种缓存，避免并发写导致的数据不一致。

2. **批量读取**:
   
   - 前端应用可能需要一次获取多个设备的状况。提供批量查询API，例如 `GET /status?devices=id1,id2,id3`，后端使用 `MGET` 命令一次性从Redis中获取，减少网络开销。

3. **数据过期与归档**:
   
   - 为Redis中的「最新状态」数据设置合理的TTL（例如7天），防止某些不再更新的设备数据永远占用内存。
   
   - 定期将「历史明细」表中的冷数据归档到更便宜的对象存储（如S3/OBS）中。

### 💎 方案选择建议

- **追求极致性能与可扩展性**：选择 **方案一（KV分离）**。这是互联网公司处理此类问题的标准范式，技术成熟，弹性好，能应对未来QPS的进一步增长。

- **追求架构简单与运维便利**：如果你的团队规模较小，希望减少技术栈复杂度，并且对毫秒级的读取延迟可以接受，那么 **方案二（单数据库+物化视图）** 是一个很好的起点。可以优先试用 **ScyllaDB** 或 **ClickHouse** 来实施。

希望这个详细的设计能帮助您构建高效的楼宇数据存储查询系统。如果您能分享数据更新的频率（这会影响写路径的设计），我可以提供更精确的建议。

# 目前数据库的CPU和IO问题

非常好！数据库IO高是一个非常典型且棘手的问题，它直接制约着系统的性能和可用性。在资源有限的情况下，我们不能简单地“堆硬件”，需要进行精准优化。

针对数据库IO高的优化，我为你梳理了一个从“低成本快速生效”到“高投入长期受益”的优化金字塔。你可以根据你们两周一个版本的节奏，分阶段实施。

### 🎯 数据库IO优化金字塔

下图清晰地展示了优化的优先级和核心策略，建议你从上到下依次推进：

---

### 🚀 **A层：应急与监控（几乎零成本，立即执行）**

在动手优化之前，必须先找到瓶颈所在。盲目的优化是最大的浪费。

1. **立即定位问题SQL**
   
   - **MySQL**：开启慢查询日志，使用 `mysqldumpslow` 或 `pt-query-digest` 工具分析。
   
   - **PostgreSQL**：查看 `pg_stat_statements` 视图，找出执行时间最长或调用次数最多的查询。
   
   - **核心目标**：找到那些 **全表扫描、缺乏索引、写操作频繁** 的SQL语句。通常，优化前20%的高IO SQL就能解决80%的问题。

2. **建立基础监控**
   
   - 使用 Prometheus + Grafana 或云厂商的监控控制台，持续观察以下指标：
     
     - `Reads/Writes per second`
     
     - `Buffer cache hit ratio`：缓冲池命中率，越高越好，低则说明内存不足，需要频繁从磁盘读。
     
     - `IOPS` 和 `Disk Latency`：确认是否达到磁盘瓶颈。

---

### 🛠️ **B层：数据库配置与硬件调优（低成本，快速生效）**

在找到问题后，一些低成本的技术选型和配置调整可以立竿见影。

1. **使用SSD硬盘（最有效的硬件升级）**
   
   - 如果还在使用机械硬盘，**毫不犹豫地升级到SSD**。这是提升IO性能性价比最高的方案，性能会有数量级的提升。

2. **调整关键配置参数**
   
   - **增大缓冲池**：`innodb_buffer_pool_size`，对于MySQL，建议设置为可用物理内存的 50%-70%。更多的数据在内存中处理，直接减少磁盘IO。
   
   - **调整日志设置**：适当增大 `innodb_log_file_size`，可以减少日志刷盘的频率。

3. **引入连接池**
   
   - 如果应用服务器频繁创建/关闭数据库连接，会带来额外开销。使用连接池可以复用连接，降低资源消耗。

---

### 🧩 **C层：查询与数据模型优化（中等投入，持续生效）**

这是优化的核心，需要开发团队深度参与，并将优化实践固化到开发流程中。

1. **索引优化策略**
   
   - **减少单次IO量**：只为必要的查询创建必要的索引。避免过多、过大的索引，因为索引在写入时会带来额外开销。
   
   - **使用覆盖索引**：让查询只需要扫描索引就能拿到全部数据，避免回表，这是减少IO的利器。
   
   - **监控索引使用率**：定期清理未使用的索引。

2. **重构问题查询**
   
   - **避免 `SELECT *`**：只取需要的字段，特别是不要查询包含 `TEXT/BLOB` 的大字段。
   
   - **优化分页查询**：对于 `LIMIT N, M` 这种深度分页，使用 `WHERE id > ? LIMIT M` 来优化，避免大量数据偏移。
   
   - **批量操作代替循环**：在代码中，尽量使用批量插入/更新，而不是在循环中执行单条操作。

3. **数据归档与TTL**
   
   - **冷热数据分离**：根据业务逻辑，将历史数据（如6个月前的订单、日志）归档到历史表，或者使用TTL自动清理。这是减轻主表压力的“大杀器”。

---

### 🏗️ **D层：架构优化（高投入，长期受益）**

当单机数据库达到极限时，需要考虑架构上的扩展。

1. **引入读写分离**
   
   - **模式**：使用一个主库负责写，多个从库负责读，通过负载均衡将读请求分发到从库。
   
   - **收益**：这是分摊读IO压力的标准做法。在你们2周迭代的节奏下，可以利用这个架构将一些报表查询、复杂分析等重IO操作定向到专门的从库。
   
   - **挑战**：需要处理主从同步延迟带来的数据不一致问题。

2. **分库分表**
   
   - 这是最终的“大招”。当单表数据量过大（如千万级以上）时，IO会成为严重瓶颈。
   
   - **方式**：根据业务逻辑进行水平拆分或垂直拆分。
   
   - **代价**：会极大地增加应用系统的复杂性，对团队要求高。**在资源有限的情况下，应作为最后的选择。**

### 💡 针对“2周一个版本”的特别建议

- **将优化任务拆解到每个迭代**：不要试图在一个版本里解决所有问题。比如：
  
  - **迭代1**：搭建监控，找出Top 3 慢SQL。
  
  - **迭代2**：优化这3个慢SQL，并建立索引规范。
  
  - **迭代3**：实施数据归档方案。

- **固化优化流程**：在CI/CD流程中加入SQL审核步骤，避免性能回归。

- **优先采用“站在数据库角度”的优化**：比如升级SSD、调整参数，这类优化对应用代码透明，不会影响你们的快速发布节奏。

**你的下一步行动建议：**

1. **立即行动**：从A层开始，在本周内定位出导致IO高的最主要原因（很可能是几条慢SQL或缺失的索引）。

2. **短期规划**：在下一个或下两个迭代中，实施B层和C层的优化，比如优化那几条慢SQL。

3. **长期规划**：如果IO问题持续存在，开始调研和设计读写分离方案。

希望这个分层的优化思路能帮助你理清头绪，一步步地将数据库IO降下来。如果你能分享具体的数据库类型和发现的典型慢SQL模式，我可以给出更具体的建议。
